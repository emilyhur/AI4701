{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import re\n",
    "from cleantext import clean\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Copy of Bot Data.xlsx')\n",
    "#convert text to features \n",
    "\n",
    "#convert text to lower case \n",
    "df['biography']=df['biography'].str.lower()\n",
    "df['comment']=df['comment'].str.lower()\n",
    "\n",
    "#expand contractions \n",
    "contractions_dict = {\"aren't\": \"are not\", \"don't\": \"do not\", \"Don't\": \"do not\", \"I'm\": \"I am\", \"i'm\": \"I am\", \n",
    "                    \"it's\": \"it is\", \"y'all\": \"you all\", \"Y'all\": \"you all\", \"didn't\": \"did not\", \"won't\": \"will not\",\n",
    "                   \"I'll\": \"I will\", \"i'll\": \"I will\", \"can't\": \"can not\"}\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(text, expand_dict):\n",
    "    def replace(match):\n",
    "        return expand_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "df['biography']=df['biography'].apply(lambda x:expand_contractions(x, contractions_dict ))\n",
    "df['comment']=df['comment'].apply(lambda x:expand_contractions(x, contractions_dict))\n",
    "\n",
    "#remove punctuation (%, ', !)\n",
    "df['biography'] = df['biography'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "df['comment'] = df['comment'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "\n",
    "bios=df['biography'].astype(str)\n",
    "comments=df['comment']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out emojis \n",
    "new_bios=[]\n",
    "for b in bios: \n",
    "    temp=clean(b, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_bios.append('None')\n",
    "    else: \n",
    "        new_bios.append(temp)\n",
    "new_comments=[]\n",
    "for c in comments:\n",
    "    temp=clean(c, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_comments.append('None')\n",
    "    else: \n",
    "        new_comments.append(temp)\n",
    "df_filtered=df.copy()\n",
    "df_filtered['biography']=new_bios\n",
    "df_filtered['comment']=new_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100k</th>\n",
       "      <th>10k</th>\n",
       "      <th>12</th>\n",
       "      <th>12600</th>\n",
       "      <th>127491</th>\n",
       "      <th>...</th>\n",
       "      <th>youtubechcd3chxjkthat</th>\n",
       "      <th>youtubecomchannelucokk65muctgbypbguysemathis</th>\n",
       "      <th>youtubecomchannelucssxa8e6u1cvojcvelxugw</th>\n",
       "      <th>yt</th>\n",
       "      <th>zainab</th>\n",
       "      <th>zeldon</th>\n",
       "      <th>zero</th>\n",
       "      <th>zilahi</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 1810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     09  10  100  1000  10000  100k  10k  12  12600  127491  ...  \\\n",
       "0     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "1     0   1    0     0      0     0    0   0      0       0  ...   \n",
       "2     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "3     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "4     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "..   ..  ..  ...   ...    ...   ...  ...  ..    ...     ...  ...   \n",
       "246   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "247   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "248   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "249   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "250   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "\n",
       "     youtubechcd3chxjkthat  youtubecomchannelucokk65muctgbypbguysemathis  \\\n",
       "0                        0                                             0   \n",
       "1                        0                                             0   \n",
       "2                        0                                             0   \n",
       "3                        0                                             0   \n",
       "4                        0                                             0   \n",
       "..                     ...                                           ...   \n",
       "246                      0                                             0   \n",
       "247                      0                                             0   \n",
       "248                      0                                             0   \n",
       "249                      0                                             0   \n",
       "250                      0                                             0   \n",
       "\n",
       "     youtubecomchannelucssxa8e6u1cvojcvelxugw  yt  zainab  zeldon  zero  \\\n",
       "0                                           0   0       0       0     0   \n",
       "1                                           0   0       0       0     0   \n",
       "2                                           0   0       0       0     0   \n",
       "3                                           0   0       0       0     0   \n",
       "4                                           0   0       0       0     0   \n",
       "..                                        ...  ..     ...     ...   ...   \n",
       "246                                         0   0       0       0     0   \n",
       "247                                         0   0       0       0     0   \n",
       "248                                         0   0       0       0     0   \n",
       "249                                         0   0       0       0     0   \n",
       "250                                         0   0       0       0     0   \n",
       "\n",
       "     zilahi  zooming  zu  \n",
       "0         0        0   0  \n",
       "1         0        0   0  \n",
       "2         0        0   0  \n",
       "3         0        0   0  \n",
       "4         0        0   0  \n",
       "..      ...      ...  ..  \n",
       "246       0        0   0  \n",
       "247       0        0   0  \n",
       "248       0        0   0  \n",
       "249       0        0   0  \n",
       "250       0        0   0  \n",
       "\n",
       "[251 rows x 1810 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine text into one string \n",
    "df_filtered['combined']=df_filtered['biography'] + '' + df_filtered['comment']\n",
    "\n",
    "#train and test set split \n",
    "train_set, test_set= train_test_split(\n",
    "df_filtered, test_size=.2, random_state=0)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer1 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer1.fit(train_set['combined'])\n",
    "text_array = vectorizer1.transform(train_set['combined']).toarray()\n",
    "text_df = pd.DataFrame(data=text_array,columns = vectorizer1.get_feature_names())\n",
    "text_df\n",
    "#can't apply the transform to separate columns because that leads to duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100k</th>\n",
       "      <th>10k</th>\n",
       "      <th>12</th>\n",
       "      <th>12600</th>\n",
       "      <th>127491</th>\n",
       "      <th>...</th>\n",
       "      <th>youtubechcd3chxjkthat</th>\n",
       "      <th>youtubecomchannelucokk65muctgbypbguysemathis</th>\n",
       "      <th>youtubecomchannelucssxa8e6u1cvojcvelxugw</th>\n",
       "      <th>yt</th>\n",
       "      <th>zainab</th>\n",
       "      <th>zeldon</th>\n",
       "      <th>zero</th>\n",
       "      <th>zilahi</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 1810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     09  10  100  1000  10000  100k  10k  12  12600  127491  ...  \\\n",
       "0     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "1     0   1    0     0      0     0    0   0      0       0  ...   \n",
       "2     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "3     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "4     0   0    0     0      0     0    0   0      0       0  ...   \n",
       "..   ..  ..  ...   ...    ...   ...  ...  ..    ...     ...  ...   \n",
       "246   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "247   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "248   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "249   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "250   0   0    0     0      0     0    0   0      0       0  ...   \n",
       "\n",
       "     youtubechcd3chxjkthat  youtubecomchannelucokk65muctgbypbguysemathis  \\\n",
       "0                        0                                             0   \n",
       "1                        0                                             0   \n",
       "2                        0                                             0   \n",
       "3                        0                                             0   \n",
       "4                        0                                             0   \n",
       "..                     ...                                           ...   \n",
       "246                      0                                             0   \n",
       "247                      0                                             0   \n",
       "248                      0                                             0   \n",
       "249                      0                                             0   \n",
       "250                      0                                             0   \n",
       "\n",
       "     youtubecomchannelucssxa8e6u1cvojcvelxugw  yt  zainab  zeldon  zero  \\\n",
       "0                                           0   0       0       0     0   \n",
       "1                                           0   0       0       0     0   \n",
       "2                                           0   0       0       0     0   \n",
       "3                                           0   0       0       0     0   \n",
       "4                                           0   0       0       0     0   \n",
       "..                                        ...  ..     ...     ...   ...   \n",
       "246                                         0   0       0       0     0   \n",
       "247                                         0   0       0       0     0   \n",
       "248                                         0   0       0       0     0   \n",
       "249                                         0   0       0       0     0   \n",
       "250                                         0   0       0       0     0   \n",
       "\n",
       "     zilahi  zooming  zu  \n",
       "0         0        0   0  \n",
       "1         0        0   0  \n",
       "2         0        0   0  \n",
       "3         0        0   0  \n",
       "4         0        0   0  \n",
       "..      ...      ...  ..  \n",
       "246       0        0   0  \n",
       "247       0        0   0  \n",
       "248       0        0   0  \n",
       "249       0        0   0  \n",
       "250       0        0   0  \n",
       "\n",
       "[251 rows x 1810 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variables are binary so don't need to be normalized\n",
    "#apply a low variance filter \n",
    "cols= text_df.columns\n",
    "variance1 = text_df.var()\n",
    "filtered_cols1 = [ ]\n",
    "for i in range(0,len(variance1)):\n",
    "    if variance1[i]>=0.006: #threshold for variance is 1%, don't want to include constant variables\n",
    "        filtered_cols1.append(cols[i])\n",
    "# filtered_cols = cols, so none of the remaining columns are constant with a variance of 0\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features: goes from 1810 to 473! \n",
    "text_df=text_df[filtered_cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=text_df\n",
    "Y_train=train_set['bot classification (0-not a bot, 1-bot)']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "text_classifier=classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming bio and comments separately\n",
    "vectorizer2 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer3 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer2.fit(train_set['biography'])\n",
    "vectorizer3.fit(train_set['comment'])\n",
    "bio_array = vectorizer2.transform(train_set['biography']).toarray()\n",
    "bio_df = pd.DataFrame(data=bio_array,columns = vectorizer2.get_feature_names())\n",
    "comment_array = vectorizer3.transform(train_set['comment']).toarray()\n",
    "comment_df = pd.DataFrame(data=comment_array,columns = vectorizer3.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter bio and comment features\n",
    "cols= bio_df.columns\n",
    "variance1 = bio_df.var()\n",
    "filtered_cols2 = [ ]\n",
    "for i in range(0,len(variance1)):\n",
    "    if variance1[i]>=0.006: #threshold for variance is 1%, don't want to include constant variables\n",
    "        filtered_cols2.append(cols[i])\n",
    "bio_df=bio_df[filtered_cols2]\n",
    "\n",
    "cols= comment_df.columns\n",
    "variance1 = comment_df.var()\n",
    "filtered_cols3 = [ ]\n",
    "for i in range(0,len(variance1)):\n",
    "    if variance1[i]>=0.006: #threshold for variance is 1%, don't want to include constant variables\n",
    "        filtered_cols3.append(cols[i])\n",
    "comment_df=comment_df[filtered_cols3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify using bio df\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(bio_df, Y_train)\n",
    "bio_classifier=classifier2.predict(bio_df)\n",
    "\n",
    "#classify using comment df \n",
    "classifier3 = LogisticRegression()\n",
    "classifier3.fit(comment_df, Y_train)\n",
    "comment_classifier=classifier3.predict(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge bio and comment dataframes to output one feature \n",
    "#this uses a different count vector for bio and comments, unlike the first classifier that concatenated \n",
    "#the two into one string \n",
    "\n",
    "df_combined=pd.DataFrame()\n",
    "df_combined=pd.concat([comment_df, bio_df],axis=1)\n",
    "classifier4 = LogisticRegression()\n",
    "classifier4.fit(df_combined, Y_train)\n",
    "text_classifier2=classifier4.predict(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#normalize the training dataset features (followers, following, etc)\n",
    "train_set_filtered=train_set[['Username', 'Follower Count', 'Following Count',\n",
    "       'Follower/Following Ratio', 'Number of posts', '# of likes on comment ', 'time of comment after post (minutes)', 'bot classification (0-not a bot, 1-bot)']]\n",
    "df_normalized=train_set_filtered.copy()\n",
    "numerical_cols=['Follower Count', 'Following Count',\n",
    "       'Follower/Following Ratio', 'Number of posts', '# of likes on comment ', 'time of comment after post (minutes)']\n",
    "for c in numerical_cols:\n",
    "    df_normalized[c]= (train_set_filtered[c] - train_set_filtered[c].min()) / (train_set_filtered[c].max() - train_set_filtered[c].min())\n",
    "df_normalized=df_normalized.set_index('Username')\n",
    "\n",
    "#normalize test set \n",
    "test_normalized=test_set.copy()\n",
    "test_normalized=test_normalized[['Username','Follower Count', 'Following Count',\n",
    "       'Follower/Following Ratio', 'Number of posts', '# of likes on comment ', 'time of comment after post (minutes)', 'bot classification (0-not a bot, 1-bot)']]\n",
    "for c in numerical_cols: \n",
    "    test_normalized[c]= (test_normalized[c] - test_normalized[c].min()) / (test_normalized[c].max() - test_normalized[c].min())  \n",
    "test_normalized=test_normalized.set_index('Username')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.873015873015873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-dbe5ba1e6b8a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['combined']=test_set['biography'] + '' + test_set['comment']\n"
     ]
    }
   ],
   "source": [
    "#try text classifying as a feature itself- vocabulary generated grouping bio and comments together \n",
    "X_train1=df_normalized.copy()\n",
    "X_train1['text_classifier']=text_classifier\n",
    "Y_train=X_train1['bot classification (0-not a bot, 1-bot)']\n",
    "X_train1=X_train1.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "\n",
    "test_set['combined']=test_set['biography'] + '' + test_set['comment']\n",
    "text_array_test = vectorizer1.transform(test_set['combined']).toarray()\n",
    "text_df_test = pd.DataFrame(data=text_array_test,columns = vectorizer1.get_feature_names())\n",
    "text_df_test=text_df_test[filtered_cols1]\n",
    "text_classifier_test=classifier.predict(text_df_test)\n",
    "X_test1=test_normalized.copy()\n",
    "X_test1['text_classifier']=text_classifier_test\n",
    "Y_test=X_test1['bot classification (0-not a bot, 1-bot)']\n",
    "X_test1=X_test1.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "final_classifier1 = LogisticRegression()\n",
    "final_classifier1.fit(X_train1, Y_train)\n",
    "score = final_classifier1.score(X_test1, Y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#separate text classifying into two features: bio and comments \n",
    "X_train2=df_normalized.copy()\n",
    "X_train2['comment_classifier']=comment_classifier\n",
    "X_train2['bio_classifier']=bio_classifier\n",
    "X_train2=X_train2.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "\n",
    "bio_array_test = vectorizer2.transform(test_set['biography']).toarray()\n",
    "bio_df_test = pd.DataFrame(data=bio_array_test,columns = vectorizer2.get_feature_names())\n",
    "comment_array_test = vectorizer3.transform(test_set['comment']).toarray()\n",
    "comment_df_test = pd.DataFrame(data=comment_array_test,columns = vectorizer3.get_feature_names())\n",
    "bio_df_test=bio_df_test[filtered_cols2]\n",
    "comment_df_test=comment_df_test[filtered_cols3]\n",
    "X_test2=test_normalized.copy()\n",
    "bio_classifier_test=classifier2.predict(bio_df_test)\n",
    "comment_classifier_test=classifier3.predict(comment_df_test)\n",
    "X_test2['comment_classifier']=comment_classifier_test\n",
    "X_test2['bio_classifier']=bio_classifier_test\n",
    "X_test2=X_test2.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "final_classifier2 = LogisticRegression()\n",
    "final_classifier2.fit(X_train2, Y_train)\n",
    "score2 = final_classifier2.score(X_test2, Y_test)\n",
    "print(\"Accuracy:\", score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "##try text classifying as ONE feature- vocabulary generated separately for bio and comments \n",
    "X_train3=df_normalized.copy()\n",
    "X_train3['text_classifier']=text_classifier2\n",
    "X_train3=X_train3.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "\n",
    "df_combined_test=pd.concat([comment_df_test, bio_df_test],axis=1)\n",
    "X_test3=test_normalized.copy()\n",
    "text_classifier2_test=classifier4.predict(df_combined_test)\n",
    "X_test3['textclassifier']=text_classifier2_test\n",
    "\n",
    "X_test3=X_test3.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "final_classifier3 = LogisticRegression()\n",
    "final_classifier3.fit(X_train3, Y_train)\n",
    "score3 = final_classifier3.score(X_test3, Y_test)\n",
    "print(\"Accuracy:\", score3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
