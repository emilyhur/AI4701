{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from cleantext import clean\n",
    "import string\n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randrange\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0a6b81040>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use for models 1 and 2\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "def create_model_basic():\n",
    "    model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Use for models 3 and 4\n",
    "def create_model_advanced():\n",
    "    data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height, img_width,3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "  ])\n",
    "\n",
    "    model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model_basic()\n",
    "#model = create_model_advanced()\n",
    "\n",
    "# Load in model 1\n",
    "model1 = create_model_basic()\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "model1.load_weights(checkpoint_path)\n",
    "\n",
    "# Load in model 2\n",
    "model2 = create_model_advanced()\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to classify images \n",
    "def evaluate_picture(model, filename):\n",
    "    try: \n",
    "        img_path = filename\n",
    "#         print(img_path)\n",
    "        img = tf.keras.utils.load_img(\n",
    "            img_path, target_size=(img_height, img_width)\n",
    "      )\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        class_names = ['bots', 'people']\n",
    "#         print(\n",
    "#           \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#           .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "#       )\n",
    "        result = class_names[np.argmax(score)]\n",
    "        if result == 'bots':\n",
    "            return 1\n",
    "        return 0\n",
    "    except: \n",
    "        return np.nan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle  \n",
    "import numpy as np\n",
    "\n",
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text\n",
    "#instead of removing emojis, converts them to text \n",
    "df=pd.read_excel('Copy of Bot Data.xlsx')\n",
    "\n",
    "#convert text to lower case \n",
    "df['biography']=df['biography'].str.lower()\n",
    "df['comment']=df['comment'].str.lower()\n",
    "\n",
    "#expand contractions \n",
    "contractions_dict = {\"aren't\": \"are not\", \"don't\": \"do not\", \"Don't\": \"do not\", \"I'm\": \"I am\", \"i'm\": \"I am\", \n",
    "                    \"it's\": \"it is\", \"y'all\": \"you all\", \"Y'all\": \"you all\", \"didn't\": \"did not\", \"won't\": \"will not\",\n",
    "                   \"I'll\": \"I will\", \"i'll\": \"I will\", \"can't\": \"can not\"}\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(text, expand_dict):\n",
    "    def replace(match):\n",
    "        return expand_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "df['biography']=df['biography'].apply(lambda x:expand_contractions(x, contractions_dict ))\n",
    "df['comment']=df['comment'].apply(lambda x:expand_contractions(x, contractions_dict))\n",
    "\n",
    "bios=df['biography'].astype(str)\n",
    "usernames=df['Username']\n",
    "comments=df['comment']\n",
    "new_bios=[]\n",
    "for b in bios: \n",
    "    temp=convert_emojis_to_word(b)\n",
    "    new_bios.append(temp)\n",
    "new_comments=[]\n",
    "for c in comments:\n",
    "    temp=convert_emojis_to_word(c)\n",
    "    new_comments.append(temp)\n",
    "df_filtered=df.copy()\n",
    "df_filtered['biography']=new_bios\n",
    "df_filtered['comment']=new_comments\n",
    "from cleantext import clean\n",
    "\n",
    "new_bios=[]\n",
    "for b in df_filtered['biography']: \n",
    "    temp=clean(b, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_bios.append('None')\n",
    "    else: \n",
    "        new_bios.append(temp)\n",
    "new_comments=[]\n",
    "for c in df_filtered['comment']:\n",
    "    temp=clean(c, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_comments.append('None')\n",
    "    else: \n",
    "        new_comments.append(temp)\n",
    "\n",
    "df_filtered['biography']=new_bios\n",
    "df_filtered['comment']=new_comments\n",
    "df_filtered['combined']=df_filtered['biography'] + ' ' + df_filtered['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Following Count</th>\n",
       "      <th>Follower/Following Ratio</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th>biography</th>\n",
       "      <th># of likes on comment</th>\n",
       "      <th>comment</th>\n",
       "      <th>time of comment after post (minutes)</th>\n",
       "      <th>combined</th>\n",
       "      <th>image_value</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>metalheadkjk</td>\n",
       "      <td>2372</td>\n",
       "      <td>297</td>\n",
       "      <td>7.986532</td>\n",
       "      <td>25</td>\n",
       "      <td>i'm kurt kennedy from portland tennessee!! i l...</td>\n",
       "      <td>0</td>\n",
       "      <td>the nashville predators suck</td>\n",
       "      <td>12</td>\n",
       "      <td>i'm kurt kennedy from portland tennessee!! i l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>dsreis</td>\n",
       "      <td>912</td>\n",
       "      <td>2412</td>\n",
       "      <td>0.378109</td>\n",
       "      <td>295</td>\n",
       "      <td>brasileiro | lds | married to the love of my l...</td>\n",
       "      <td>440</td>\n",
       "      <td>custody papers. they were never married.</td>\n",
       "      <td>3</td>\n",
       "      <td>brasileiro | lds | married to the love of my l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ulan_sevbeni</td>\n",
       "      <td>3401</td>\n",
       "      <td>108</td>\n",
       "      <td>31.490741</td>\n",
       "      <td>0</td>\n",
       "      <td>umudumu kaybettim:))</td>\n",
       "      <td>0</td>\n",
       "      <td>for a start i deposited $15,000 to test thewat...</td>\n",
       "      <td>2</td>\n",
       "      <td>umudumu kaybettim:)) for a start i deposited $...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>earlenemega</td>\n",
       "      <td>26</td>\n",
       "      <td>268</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0</td>\n",
       "      <td>linkr.bio/earlenemega</td>\n",
       "      <td>96</td>\n",
       "      <td>hushed_facetag your friends who do not have a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>linkr.bio/earlenemega hushed_facetag your frie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>catherine.wilson_</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>backup-file-2861ba.netlify.app</td>\n",
       "      <td>0</td>\n",
       "      <td>do not watch my stories !!</td>\n",
       "      <td>2</td>\n",
       "      <td>backup-file-2861ba.netlify.app do not watch my...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>jesilakunil67</td>\n",
       "      <td>34</td>\n",
       "      <td>238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>clinquant-cranachan-595473.netlify.app</td>\n",
       "      <td>23</td>\n",
       "      <td>how about my stories,keep it or leave it?</td>\n",
       "      <td>1</td>\n",
       "      <td>clinquant-cranachan-595473.netlify.app how abo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>harris_gilpin</td>\n",
       "      <td>2532</td>\n",
       "      <td>1504</td>\n",
       "      <td>1.683511</td>\n",
       "      <td>9</td>\n",
       "      <td>od fearingdove private figure ! manmedium-dark...</td>\n",
       "      <td>0</td>\n",
       "      <td>i am funding heavy_dollar_sign5,000 for the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>od fearingdove private figure ! manmedium-dark...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gabriella.jaz11</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0</td>\n",
       "      <td>gabriella new account help support beating_hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>what do you guys do when you take a shower? fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>gabriella new account help support beating_hea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>clrkkk.amanda93</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>linkr.bio/amanda-clark</td>\n",
       "      <td>163</td>\n",
       "      <td>charmingly!</td>\n",
       "      <td>1</td>\n",
       "      <td>linkr.bio/amanda-clark charmingly!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>richhomie.sol</td>\n",
       "      <td>531</td>\n",
       "      <td>80</td>\n",
       "      <td>6.637500</td>\n",
       "      <td>30</td>\n",
       "      <td>bank finance when there's hope for the future,...</td>\n",
       "      <td>3</td>\n",
       "      <td>wearing glasses lmao</td>\n",
       "      <td>9</td>\n",
       "      <td>bank finance when there's hope for the future,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Username  Follower Count  Following Count  \\\n",
       "170       metalheadkjk            2372              297   \n",
       "282             dsreis             912             2412   \n",
       "132       ulan_sevbeni            3401              108   \n",
       "65         earlenemega              26              268   \n",
       "24   catherine.wilson_               7               35   \n",
       "..                 ...             ...              ...   \n",
       "156      jesilakunil67              34              238   \n",
       "123      harris_gilpin            2532             1504   \n",
       "15     gabriella.jaz11               4               39   \n",
       "125    clrkkk.amanda93             571                4   \n",
       "265      richhomie.sol             531               80   \n",
       "\n",
       "     Follower/Following Ratio  Number of posts  \\\n",
       "170                  7.986532               25   \n",
       "282                  0.378109              295   \n",
       "132                 31.490741                0   \n",
       "65                   0.097015                0   \n",
       "24                   0.200000                2   \n",
       "..                        ...              ...   \n",
       "156                  0.142857                0   \n",
       "123                  1.683511                9   \n",
       "15                   0.102564                0   \n",
       "125                142.750000                3   \n",
       "265                  6.637500               30   \n",
       "\n",
       "                                             biography  \\\n",
       "170  i'm kurt kennedy from portland tennessee!! i l...   \n",
       "282  brasileiro | lds | married to the love of my l...   \n",
       "132                               umudumu kaybettim:))   \n",
       "65                               linkr.bio/earlenemega   \n",
       "24                      backup-file-2861ba.netlify.app   \n",
       "..                                                 ...   \n",
       "156             clinquant-cranachan-595473.netlify.app   \n",
       "123  od fearingdove private figure ! manmedium-dark...   \n",
       "15   gabriella new account help support beating_hea...   \n",
       "125                             linkr.bio/amanda-clark   \n",
       "265  bank finance when there's hope for the future,...   \n",
       "\n",
       "     # of likes on comment   \\\n",
       "170                       0   \n",
       "282                     440   \n",
       "132                       0   \n",
       "65                       96   \n",
       "24                        0   \n",
       "..                      ...   \n",
       "156                      23   \n",
       "123                       0   \n",
       "15                        1   \n",
       "125                     163   \n",
       "265                       3   \n",
       "\n",
       "                                               comment  \\\n",
       "170                       the nashville predators suck   \n",
       "282           custody papers. they were never married.   \n",
       "132  for a start i deposited $15,000 to test thewat...   \n",
       "65   hushed_facetag your friends who do not have a ...   \n",
       "24                          do not watch my stories !!   \n",
       "..                                                 ...   \n",
       "156          how about my stories,keep it or leave it?   \n",
       "123  i am funding heavy_dollar_sign5,000 for the fi...   \n",
       "15   what do you guys do when you take a shower? fa...   \n",
       "125                                        charmingly!   \n",
       "265                               wearing glasses lmao   \n",
       "\n",
       "     time of comment after post (minutes)  \\\n",
       "170                                    12   \n",
       "282                                     3   \n",
       "132                                     2   \n",
       "65                                      0   \n",
       "24                                      2   \n",
       "..                                    ...   \n",
       "156                                     1   \n",
       "123                                     1   \n",
       "15                                      0   \n",
       "125                                     1   \n",
       "265                                     9   \n",
       "\n",
       "                                              combined  image_value  \\\n",
       "170  i'm kurt kennedy from portland tennessee!! i l...          0.0   \n",
       "282  brasileiro | lds | married to the love of my l...          0.0   \n",
       "132  umudumu kaybettim:)) for a start i deposited $...          1.0   \n",
       "65   linkr.bio/earlenemega hushed_facetag your frie...          1.0   \n",
       "24   backup-file-2861ba.netlify.app do not watch my...          1.0   \n",
       "..                                                 ...          ...   \n",
       "156  clinquant-cranachan-595473.netlify.app how abo...          1.0   \n",
       "123  od fearingdove private figure ! manmedium-dark...          0.0   \n",
       "15   gabriella new account help support beating_hea...          1.0   \n",
       "125                 linkr.bio/amanda-clark charmingly!          1.0   \n",
       "265  bank finance when there's hope for the future,...          0.0   \n",
       "\n",
       "     classification  \n",
       "170               0  \n",
       "282               0  \n",
       "132               1  \n",
       "65                1  \n",
       "24                1  \n",
       "..              ...  \n",
       "156               1  \n",
       "123               1  \n",
       "15                1  \n",
       "125               1  \n",
       "265               0  \n",
       "\n",
       "[314 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered=df_filtered.sample(frac=1, random_state=10)\n",
    "image_classifications=[]\n",
    "usernames=df_filtered['Username']\n",
    "for user in usernames:\n",
    "    filename=user+'.png'\n",
    "    classification=evaluate_picture(model1, filename)\n",
    "    image_classifications.append(classification)\n",
    "real_values=df_filtered['bot classification (0-not a bot, 1-bot)']\n",
    "df_filtered=df_filtered.drop(['bot classification (0-not a bot, 1-bot)'], axis=1)\n",
    "df_filtered['image_value']=image_classifications\n",
    "df_filtered['classification']=real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>account</th>\n",
       "      <th>after</th>\n",
       "      <th>ain</th>\n",
       "      <th>app</th>\n",
       "      <th>athlete</th>\n",
       "      <th>bf</th>\n",
       "      <th>bio</th>\n",
       "      <th>bit</th>\n",
       "      <th>...</th>\n",
       "      <th>youtube</th>\n",
       "      <th>index</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Following Count</th>\n",
       "      <th>Follower/Following Ratio</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th># of likes on comment</th>\n",
       "      <th>time of comment after post (minutes)</th>\n",
       "      <th>image_value</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>2372</td>\n",
       "      <td>297</td>\n",
       "      <td>7.986532</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>912</td>\n",
       "      <td>2412</td>\n",
       "      <td>0.378109</td>\n",
       "      <td>295</td>\n",
       "      <td>440</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>3401</td>\n",
       "      <td>108</td>\n",
       "      <td>31.490741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>268</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>34</td>\n",
       "      <td>238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>2532</td>\n",
       "      <td>1504</td>\n",
       "      <td>1.683511</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>531</td>\n",
       "      <td>80</td>\n",
       "      <td>6.637500</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  100  account  after  ain  app  athlete  bf  bio  bit  ...  youtube  \\\n",
       "0      0    0        0      0    0    0        0   0    0    0  ...        0   \n",
       "1      0    0        0      0    0    0        0   0    0    0  ...        0   \n",
       "2      1    1        0      1    0    0        0   0    0    0  ...        0   \n",
       "3      0    0        0      0    0    0        0   0    1    0  ...        0   \n",
       "4      0    0        0      0    0    1        0   0    0    0  ...        0   \n",
       "..   ...  ...      ...    ...  ...  ...      ...  ..  ...  ...  ...      ...   \n",
       "282    0    0        0      0    0    1        0   0    0    0  ...        0   \n",
       "283    1    0        0      0    0    0        0   0    0    0  ...        0   \n",
       "284    0    0        1      0    0    0        0   0    0    0  ...        0   \n",
       "285    0    0        0      0    0    0        0   0    1    0  ...        0   \n",
       "286    0    0        0      0    0    0        0   0    0    0  ...        0   \n",
       "\n",
       "     index  Follower Count  Following Count  Follower/Following Ratio  \\\n",
       "0      170            2372              297                  7.986532   \n",
       "1      282             912             2412                  0.378109   \n",
       "2      132            3401              108                 31.490741   \n",
       "3       65              26              268                  0.097015   \n",
       "4       24               7               35                  0.200000   \n",
       "..     ...             ...              ...                       ...   \n",
       "282    156              34              238                  0.142857   \n",
       "283    123            2532             1504                  1.683511   \n",
       "284     15               4               39                  0.102564   \n",
       "285    125             571                4                142.750000   \n",
       "286    265             531               80                  6.637500   \n",
       "\n",
       "     Number of posts  # of likes on comment   \\\n",
       "0                 25                       0   \n",
       "1                295                     440   \n",
       "2                  0                       0   \n",
       "3                  0                      96   \n",
       "4                  2                       0   \n",
       "..               ...                     ...   \n",
       "282                0                      23   \n",
       "283                9                       0   \n",
       "284                0                       1   \n",
       "285                3                     163   \n",
       "286               30                       3   \n",
       "\n",
       "     time of comment after post (minutes)  image_value  classification  \n",
       "0                                      12          0.0               0  \n",
       "1                                       3          0.0               0  \n",
       "2                                       2          1.0               1  \n",
       "3                                       0          1.0               1  \n",
       "4                                       2          1.0               1  \n",
       "..                                    ...          ...             ...  \n",
       "282                                     1          1.0               1  \n",
       "283                                     1          0.0               1  \n",
       "284                                     0          1.0               1  \n",
       "285                                     1          1.0               1  \n",
       "286                                     9          0.0               0  \n",
       "\n",
       "[287 rows x 59 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifying the biographies and comments combined \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "df_filtered=df_filtered.dropna()\n",
    "\n",
    "vectorizer1 =  CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer1.fit(df_filtered['combined'])\n",
    "text_array = vectorizer1.transform(df_filtered['combined']).toarray()\n",
    "text_df = pd.DataFrame(data=text_array,columns = vectorizer1.get_feature_names())\n",
    "df_filtered\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "selector1=RFE(estimator=model, n_features_to_select=50, step=1) #chose arbitrarily to select 50 of the most important words out of 2000 to make it more manageable\n",
    "\n",
    "#split dataset into features and labels\n",
    "Y1=df_filtered['classification']\n",
    "X1=text_df\n",
    "\n",
    "#run RFE\n",
    "rfe1 = selector1.fit_transform(X1, Y1)\n",
    "filter1=(selector1.get_support())\n",
    "\n",
    "##\n",
    "#filter columns using data from RFE\n",
    "filter1=list(filter1)\n",
    "current_cols = list(X1.columns)\n",
    "\n",
    "#figure out which columns to keep\n",
    "important_cols=[]\n",
    "for index in range(len(filter1)):\n",
    "    if (filter1[index])==True:\n",
    "        important_cols.append(current_cols[index])\n",
    "text_df=text_df[important_cols]\n",
    "df_filtered=df_filtered.reset_index()\n",
    "df_combined=pd.concat([text_df, df_filtered], axis=1)\n",
    "df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_combined=df_combined.drop(['comment', 'biography', 'combined', 'Username'], axis=1)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('neural_network_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network \n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "    return stats\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "            \n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    " \n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    " \n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    " \n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    " \n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    " \n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    " \n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(neuron['output'] - expected[j])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "            \n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] -= l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\n",
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=136.754\n",
      ">epoch=1, lrate=0.100, error=114.886\n",
      ">epoch=2, lrate=0.100, error=110.117\n",
      ">epoch=3, lrate=0.100, error=101.270\n",
      ">epoch=4, lrate=0.100, error=85.387\n",
      ">epoch=5, lrate=0.100, error=64.741\n",
      ">epoch=6, lrate=0.100, error=46.384\n",
      ">epoch=7, lrate=0.100, error=33.624\n",
      ">epoch=8, lrate=0.100, error=25.574\n",
      ">epoch=9, lrate=0.100, error=20.482\n",
      ">epoch=10, lrate=0.100, error=17.112\n",
      ">epoch=11, lrate=0.100, error=14.755\n",
      ">epoch=12, lrate=0.100, error=13.018\n",
      ">epoch=13, lrate=0.100, error=11.678\n",
      ">epoch=14, lrate=0.100, error=10.605\n",
      ">epoch=15, lrate=0.100, error=9.717\n",
      ">epoch=16, lrate=0.100, error=8.965\n",
      ">epoch=17, lrate=0.100, error=8.314\n",
      ">epoch=18, lrate=0.100, error=7.743\n",
      ">epoch=19, lrate=0.100, error=7.234\n",
      ">epoch=20, lrate=0.100, error=6.776\n",
      ">epoch=21, lrate=0.100, error=6.361\n",
      ">epoch=22, lrate=0.100, error=5.982\n",
      ">epoch=23, lrate=0.100, error=5.635\n",
      ">epoch=24, lrate=0.100, error=5.315\n",
      ">epoch=25, lrate=0.100, error=5.019\n",
      ">epoch=26, lrate=0.100, error=4.745\n",
      ">epoch=27, lrate=0.100, error=4.491\n",
      ">epoch=28, lrate=0.100, error=4.254\n",
      ">epoch=29, lrate=0.100, error=4.034\n",
      ">epoch=30, lrate=0.100, error=3.830\n",
      ">epoch=31, lrate=0.100, error=3.640\n",
      ">epoch=32, lrate=0.100, error=3.462\n",
      ">epoch=33, lrate=0.100, error=3.297\n",
      ">epoch=34, lrate=0.100, error=3.144\n",
      ">epoch=35, lrate=0.100, error=3.000\n",
      ">epoch=36, lrate=0.100, error=2.866\n",
      ">epoch=37, lrate=0.100, error=2.742\n",
      ">epoch=38, lrate=0.100, error=2.625\n",
      ">epoch=39, lrate=0.100, error=2.516\n",
      ">epoch=40, lrate=0.100, error=2.414\n",
      ">epoch=41, lrate=0.100, error=2.319\n",
      ">epoch=42, lrate=0.100, error=2.230\n",
      ">epoch=43, lrate=0.100, error=2.146\n",
      ">epoch=44, lrate=0.100, error=2.067\n",
      ">epoch=45, lrate=0.100, error=1.993\n",
      ">epoch=46, lrate=0.100, error=1.924\n",
      ">epoch=47, lrate=0.100, error=1.858\n",
      ">epoch=48, lrate=0.100, error=1.797\n",
      ">epoch=49, lrate=0.100, error=1.738\n",
      ">epoch=50, lrate=0.100, error=1.683\n",
      ">epoch=51, lrate=0.100, error=1.631\n",
      ">epoch=52, lrate=0.100, error=1.582\n",
      ">epoch=53, lrate=0.100, error=1.535\n",
      ">epoch=54, lrate=0.100, error=1.491\n",
      ">epoch=55, lrate=0.100, error=1.449\n",
      ">epoch=56, lrate=0.100, error=1.409\n",
      ">epoch=57, lrate=0.100, error=1.371\n",
      ">epoch=58, lrate=0.100, error=1.335\n",
      ">epoch=59, lrate=0.100, error=1.300\n",
      ">epoch=60, lrate=0.100, error=1.267\n",
      ">epoch=61, lrate=0.100, error=1.236\n",
      ">epoch=62, lrate=0.100, error=1.206\n",
      ">epoch=63, lrate=0.100, error=1.177\n",
      ">epoch=64, lrate=0.100, error=1.149\n",
      ">epoch=65, lrate=0.100, error=1.123\n",
      ">epoch=66, lrate=0.100, error=1.098\n",
      ">epoch=67, lrate=0.100, error=1.073\n",
      ">epoch=68, lrate=0.100, error=1.050\n",
      ">epoch=69, lrate=0.100, error=1.028\n",
      ">epoch=70, lrate=0.100, error=1.006\n",
      ">epoch=71, lrate=0.100, error=0.985\n",
      ">epoch=72, lrate=0.100, error=0.966\n",
      ">epoch=73, lrate=0.100, error=0.946\n",
      ">epoch=74, lrate=0.100, error=0.928\n",
      ">epoch=75, lrate=0.100, error=0.910\n",
      ">epoch=76, lrate=0.100, error=0.893\n",
      ">epoch=77, lrate=0.100, error=0.876\n",
      ">epoch=78, lrate=0.100, error=0.860\n",
      ">epoch=79, lrate=0.100, error=0.844\n",
      ">epoch=80, lrate=0.100, error=0.829\n",
      ">epoch=81, lrate=0.100, error=0.815\n",
      ">epoch=82, lrate=0.100, error=0.801\n",
      ">epoch=83, lrate=0.100, error=0.787\n",
      ">epoch=84, lrate=0.100, error=0.774\n",
      ">epoch=85, lrate=0.100, error=0.761\n",
      ">epoch=86, lrate=0.100, error=0.749\n",
      ">epoch=87, lrate=0.100, error=0.737\n",
      ">epoch=88, lrate=0.100, error=0.725\n",
      ">epoch=89, lrate=0.100, error=0.714\n",
      ">epoch=90, lrate=0.100, error=0.703\n",
      ">epoch=91, lrate=0.100, error=0.692\n",
      ">epoch=92, lrate=0.100, error=0.682\n",
      ">epoch=93, lrate=0.100, error=0.671\n",
      ">epoch=94, lrate=0.100, error=0.662\n",
      ">epoch=95, lrate=0.100, error=0.652\n",
      ">epoch=96, lrate=0.100, error=0.643\n",
      ">epoch=97, lrate=0.100, error=0.634\n",
      ">epoch=98, lrate=0.100, error=0.625\n",
      ">epoch=99, lrate=0.100, error=0.616\n",
      ">epoch=100, lrate=0.100, error=0.608\n",
      ">epoch=101, lrate=0.100, error=0.600\n",
      ">epoch=102, lrate=0.100, error=0.592\n",
      ">epoch=103, lrate=0.100, error=0.584\n",
      ">epoch=104, lrate=0.100, error=0.576\n",
      ">epoch=105, lrate=0.100, error=0.569\n",
      ">epoch=106, lrate=0.100, error=0.562\n",
      ">epoch=107, lrate=0.100, error=0.555\n",
      ">epoch=108, lrate=0.100, error=0.548\n",
      ">epoch=109, lrate=0.100, error=0.541\n",
      ">epoch=110, lrate=0.100, error=0.534\n",
      ">epoch=111, lrate=0.100, error=0.528\n",
      ">epoch=112, lrate=0.100, error=0.522\n",
      ">epoch=113, lrate=0.100, error=0.516\n",
      ">epoch=114, lrate=0.100, error=0.510\n",
      ">epoch=115, lrate=0.100, error=0.504\n",
      ">epoch=116, lrate=0.100, error=0.498\n",
      ">epoch=117, lrate=0.100, error=0.492\n",
      ">epoch=118, lrate=0.100, error=0.487\n",
      ">epoch=119, lrate=0.100, error=0.481\n",
      ">epoch=120, lrate=0.100, error=0.476\n",
      ">epoch=121, lrate=0.100, error=0.471\n",
      ">epoch=122, lrate=0.100, error=0.466\n",
      ">epoch=123, lrate=0.100, error=0.461\n",
      ">epoch=124, lrate=0.100, error=0.456\n",
      ">epoch=125, lrate=0.100, error=0.451\n",
      ">epoch=126, lrate=0.100, error=0.446\n",
      ">epoch=127, lrate=0.100, error=0.442\n",
      ">epoch=128, lrate=0.100, error=0.437\n",
      ">epoch=129, lrate=0.100, error=0.433\n",
      ">epoch=130, lrate=0.100, error=0.429\n",
      ">epoch=131, lrate=0.100, error=0.424\n",
      ">epoch=132, lrate=0.100, error=0.420\n",
      ">epoch=133, lrate=0.100, error=0.416\n",
      ">epoch=134, lrate=0.100, error=0.412\n",
      ">epoch=135, lrate=0.100, error=0.408\n",
      ">epoch=136, lrate=0.100, error=0.404\n",
      ">epoch=137, lrate=0.100, error=0.400\n",
      ">epoch=138, lrate=0.100, error=0.397\n",
      ">epoch=139, lrate=0.100, error=0.393\n",
      ">epoch=140, lrate=0.100, error=0.389\n",
      ">epoch=141, lrate=0.100, error=0.386\n",
      ">epoch=142, lrate=0.100, error=0.382\n",
      ">epoch=143, lrate=0.100, error=0.379\n",
      ">epoch=144, lrate=0.100, error=0.375\n",
      ">epoch=145, lrate=0.100, error=0.372\n",
      ">epoch=146, lrate=0.100, error=0.369\n",
      ">epoch=147, lrate=0.100, error=0.366\n",
      ">epoch=148, lrate=0.100, error=0.362\n",
      ">epoch=149, lrate=0.100, error=0.359\n",
      ">epoch=150, lrate=0.100, error=0.356\n",
      ">epoch=151, lrate=0.100, error=0.353\n",
      ">epoch=152, lrate=0.100, error=0.350\n",
      ">epoch=153, lrate=0.100, error=0.347\n",
      ">epoch=154, lrate=0.100, error=0.345\n",
      ">epoch=155, lrate=0.100, error=0.342\n",
      ">epoch=156, lrate=0.100, error=0.339\n",
      ">epoch=157, lrate=0.100, error=0.336\n",
      ">epoch=158, lrate=0.100, error=0.333\n",
      ">epoch=159, lrate=0.100, error=0.331\n",
      ">epoch=160, lrate=0.100, error=0.328\n",
      ">epoch=161, lrate=0.100, error=0.326\n",
      ">epoch=162, lrate=0.100, error=0.323\n",
      ">epoch=163, lrate=0.100, error=0.321\n",
      ">epoch=164, lrate=0.100, error=0.318\n",
      ">epoch=165, lrate=0.100, error=0.316\n",
      ">epoch=166, lrate=0.100, error=0.313\n",
      ">epoch=167, lrate=0.100, error=0.311\n",
      ">epoch=168, lrate=0.100, error=0.309\n",
      ">epoch=169, lrate=0.100, error=0.306\n",
      ">epoch=170, lrate=0.100, error=0.304\n",
      ">epoch=171, lrate=0.100, error=0.302\n",
      ">epoch=172, lrate=0.100, error=0.300\n",
      ">epoch=173, lrate=0.100, error=0.297\n",
      ">epoch=174, lrate=0.100, error=0.295\n",
      ">epoch=175, lrate=0.100, error=0.293\n",
      ">epoch=176, lrate=0.100, error=0.291\n",
      ">epoch=177, lrate=0.100, error=0.289\n",
      ">epoch=178, lrate=0.100, error=0.287\n",
      ">epoch=179, lrate=0.100, error=0.285\n",
      ">epoch=180, lrate=0.100, error=0.283\n",
      ">epoch=181, lrate=0.100, error=0.281\n",
      ">epoch=182, lrate=0.100, error=0.279\n",
      ">epoch=183, lrate=0.100, error=0.277\n",
      ">epoch=184, lrate=0.100, error=0.275\n",
      ">epoch=185, lrate=0.100, error=0.273\n",
      ">epoch=186, lrate=0.100, error=0.272\n",
      ">epoch=187, lrate=0.100, error=0.270\n",
      ">epoch=188, lrate=0.100, error=0.268\n",
      ">epoch=189, lrate=0.100, error=0.266\n",
      ">epoch=190, lrate=0.100, error=0.265\n",
      ">epoch=191, lrate=0.100, error=0.263\n",
      ">epoch=192, lrate=0.100, error=0.261\n",
      ">epoch=193, lrate=0.100, error=0.259\n",
      ">epoch=194, lrate=0.100, error=0.258\n",
      ">epoch=195, lrate=0.100, error=0.256\n",
      ">epoch=196, lrate=0.100, error=0.255\n",
      ">epoch=197, lrate=0.100, error=0.253\n",
      ">epoch=198, lrate=0.100, error=0.251\n",
      ">epoch=199, lrate=0.100, error=0.250\n",
      ">epoch=200, lrate=0.100, error=0.248\n",
      ">epoch=201, lrate=0.100, error=0.247\n",
      ">epoch=202, lrate=0.100, error=0.245\n",
      ">epoch=203, lrate=0.100, error=0.244\n",
      ">epoch=204, lrate=0.100, error=0.242\n",
      ">epoch=205, lrate=0.100, error=0.241\n",
      ">epoch=206, lrate=0.100, error=0.239\n",
      ">epoch=207, lrate=0.100, error=0.238\n",
      ">epoch=208, lrate=0.100, error=0.236\n",
      ">epoch=209, lrate=0.100, error=0.235\n",
      ">epoch=210, lrate=0.100, error=0.234\n",
      ">epoch=211, lrate=0.100, error=0.232\n",
      ">epoch=212, lrate=0.100, error=0.231\n",
      ">epoch=213, lrate=0.100, error=0.230\n",
      ">epoch=214, lrate=0.100, error=0.228\n",
      ">epoch=215, lrate=0.100, error=0.227\n",
      ">epoch=216, lrate=0.100, error=0.226\n",
      ">epoch=217, lrate=0.100, error=0.224\n",
      ">epoch=218, lrate=0.100, error=0.223\n",
      ">epoch=219, lrate=0.100, error=0.222\n",
      ">epoch=220, lrate=0.100, error=0.221\n",
      ">epoch=221, lrate=0.100, error=0.220\n",
      ">epoch=222, lrate=0.100, error=0.218\n",
      ">epoch=223, lrate=0.100, error=0.217\n",
      ">epoch=224, lrate=0.100, error=0.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=225, lrate=0.100, error=0.215\n",
      ">epoch=226, lrate=0.100, error=0.214\n",
      ">epoch=227, lrate=0.100, error=0.212\n",
      ">epoch=228, lrate=0.100, error=0.211\n",
      ">epoch=229, lrate=0.100, error=0.210\n",
      ">epoch=230, lrate=0.100, error=0.209\n",
      ">epoch=231, lrate=0.100, error=0.208\n",
      ">epoch=232, lrate=0.100, error=0.207\n",
      ">epoch=233, lrate=0.100, error=0.206\n",
      ">epoch=234, lrate=0.100, error=0.205\n",
      ">epoch=235, lrate=0.100, error=0.204\n",
      ">epoch=236, lrate=0.100, error=0.203\n",
      ">epoch=237, lrate=0.100, error=0.202\n",
      ">epoch=238, lrate=0.100, error=0.201\n",
      ">epoch=239, lrate=0.100, error=0.200\n",
      ">epoch=240, lrate=0.100, error=0.199\n",
      ">epoch=241, lrate=0.100, error=0.198\n",
      ">epoch=242, lrate=0.100, error=0.197\n",
      ">epoch=243, lrate=0.100, error=0.196\n",
      ">epoch=244, lrate=0.100, error=0.195\n",
      ">epoch=245, lrate=0.100, error=0.194\n",
      ">epoch=246, lrate=0.100, error=0.193\n",
      ">epoch=247, lrate=0.100, error=0.192\n",
      ">epoch=248, lrate=0.100, error=0.191\n",
      ">epoch=249, lrate=0.100, error=0.190\n",
      ">epoch=250, lrate=0.100, error=0.189\n",
      ">epoch=251, lrate=0.100, error=0.188\n",
      ">epoch=252, lrate=0.100, error=0.187\n",
      ">epoch=253, lrate=0.100, error=0.186\n",
      ">epoch=254, lrate=0.100, error=0.185\n",
      ">epoch=255, lrate=0.100, error=0.184\n",
      ">epoch=256, lrate=0.100, error=0.184\n",
      ">epoch=257, lrate=0.100, error=0.183\n",
      ">epoch=258, lrate=0.100, error=0.182\n",
      ">epoch=259, lrate=0.100, error=0.181\n",
      ">epoch=260, lrate=0.100, error=0.180\n",
      ">epoch=261, lrate=0.100, error=0.179\n",
      ">epoch=262, lrate=0.100, error=0.178\n",
      ">epoch=263, lrate=0.100, error=0.178\n",
      ">epoch=264, lrate=0.100, error=0.177\n",
      ">epoch=265, lrate=0.100, error=0.176\n",
      ">epoch=266, lrate=0.100, error=0.175\n",
      ">epoch=267, lrate=0.100, error=0.174\n",
      ">epoch=268, lrate=0.100, error=0.174\n",
      ">epoch=269, lrate=0.100, error=0.173\n",
      ">epoch=270, lrate=0.100, error=0.172\n",
      ">epoch=271, lrate=0.100, error=0.171\n",
      ">epoch=272, lrate=0.100, error=0.171\n",
      ">epoch=273, lrate=0.100, error=0.170\n",
      ">epoch=274, lrate=0.100, error=0.169\n",
      ">epoch=275, lrate=0.100, error=0.168\n",
      ">epoch=276, lrate=0.100, error=0.168\n",
      ">epoch=277, lrate=0.100, error=0.167\n",
      ">epoch=278, lrate=0.100, error=0.166\n",
      ">epoch=279, lrate=0.100, error=0.165\n",
      ">epoch=280, lrate=0.100, error=0.165\n",
      ">epoch=281, lrate=0.100, error=0.164\n",
      ">epoch=282, lrate=0.100, error=0.163\n",
      ">epoch=283, lrate=0.100, error=0.163\n",
      ">epoch=284, lrate=0.100, error=0.162\n",
      ">epoch=285, lrate=0.100, error=0.161\n",
      ">epoch=286, lrate=0.100, error=0.161\n",
      ">epoch=287, lrate=0.100, error=0.160\n",
      ">epoch=288, lrate=0.100, error=0.159\n",
      ">epoch=289, lrate=0.100, error=0.159\n",
      ">epoch=290, lrate=0.100, error=0.158\n",
      ">epoch=291, lrate=0.100, error=0.157\n",
      ">epoch=292, lrate=0.100, error=0.157\n",
      ">epoch=293, lrate=0.100, error=0.156\n",
      ">epoch=294, lrate=0.100, error=0.155\n",
      ">epoch=295, lrate=0.100, error=0.155\n",
      ">epoch=296, lrate=0.100, error=0.154\n",
      ">epoch=297, lrate=0.100, error=0.154\n",
      ">epoch=298, lrate=0.100, error=0.153\n",
      ">epoch=299, lrate=0.100, error=0.152\n",
      ">epoch=300, lrate=0.100, error=0.152\n",
      ">epoch=301, lrate=0.100, error=0.151\n",
      ">epoch=302, lrate=0.100, error=0.150\n",
      ">epoch=303, lrate=0.100, error=0.150\n",
      ">epoch=304, lrate=0.100, error=0.149\n",
      ">epoch=305, lrate=0.100, error=0.149\n",
      ">epoch=306, lrate=0.100, error=0.148\n",
      ">epoch=307, lrate=0.100, error=0.148\n",
      ">epoch=308, lrate=0.100, error=0.147\n",
      ">epoch=309, lrate=0.100, error=0.146\n",
      ">epoch=310, lrate=0.100, error=0.146\n",
      ">epoch=311, lrate=0.100, error=0.145\n",
      ">epoch=312, lrate=0.100, error=0.145\n",
      ">epoch=313, lrate=0.100, error=0.144\n",
      ">epoch=314, lrate=0.100, error=0.144\n",
      ">epoch=315, lrate=0.100, error=0.143\n",
      ">epoch=316, lrate=0.100, error=0.143\n",
      ">epoch=317, lrate=0.100, error=0.142\n",
      ">epoch=318, lrate=0.100, error=0.142\n",
      ">epoch=319, lrate=0.100, error=0.141\n",
      ">epoch=320, lrate=0.100, error=0.140\n",
      ">epoch=321, lrate=0.100, error=0.140\n",
      ">epoch=322, lrate=0.100, error=0.139\n",
      ">epoch=323, lrate=0.100, error=0.139\n",
      ">epoch=324, lrate=0.100, error=0.138\n",
      ">epoch=325, lrate=0.100, error=0.138\n",
      ">epoch=326, lrate=0.100, error=0.137\n",
      ">epoch=327, lrate=0.100, error=0.137\n",
      ">epoch=328, lrate=0.100, error=0.136\n",
      ">epoch=329, lrate=0.100, error=0.136\n",
      ">epoch=330, lrate=0.100, error=0.135\n",
      ">epoch=331, lrate=0.100, error=0.135\n",
      ">epoch=332, lrate=0.100, error=0.134\n",
      ">epoch=333, lrate=0.100, error=0.134\n",
      ">epoch=334, lrate=0.100, error=0.133\n",
      ">epoch=335, lrate=0.100, error=0.133\n",
      ">epoch=336, lrate=0.100, error=0.133\n",
      ">epoch=337, lrate=0.100, error=0.132\n",
      ">epoch=338, lrate=0.100, error=0.132\n",
      ">epoch=339, lrate=0.100, error=0.131\n",
      ">epoch=340, lrate=0.100, error=0.131\n",
      ">epoch=341, lrate=0.100, error=0.130\n",
      ">epoch=342, lrate=0.100, error=0.130\n",
      ">epoch=343, lrate=0.100, error=0.129\n",
      ">epoch=344, lrate=0.100, error=0.129\n",
      ">epoch=345, lrate=0.100, error=0.128\n",
      ">epoch=346, lrate=0.100, error=0.128\n",
      ">epoch=347, lrate=0.100, error=0.128\n",
      ">epoch=348, lrate=0.100, error=0.127\n",
      ">epoch=349, lrate=0.100, error=0.127\n",
      ">epoch=350, lrate=0.100, error=0.126\n",
      ">epoch=351, lrate=0.100, error=0.126\n",
      ">epoch=352, lrate=0.100, error=0.125\n",
      ">epoch=353, lrate=0.100, error=0.125\n",
      ">epoch=354, lrate=0.100, error=0.125\n",
      ">epoch=355, lrate=0.100, error=0.124\n",
      ">epoch=356, lrate=0.100, error=0.124\n",
      ">epoch=357, lrate=0.100, error=0.123\n",
      ">epoch=358, lrate=0.100, error=0.123\n",
      ">epoch=359, lrate=0.100, error=0.123\n",
      ">epoch=360, lrate=0.100, error=0.122\n",
      ">epoch=361, lrate=0.100, error=0.122\n",
      ">epoch=362, lrate=0.100, error=0.121\n",
      ">epoch=363, lrate=0.100, error=0.121\n",
      ">epoch=364, lrate=0.100, error=0.121\n",
      ">epoch=365, lrate=0.100, error=0.120\n",
      ">epoch=366, lrate=0.100, error=0.120\n",
      ">epoch=367, lrate=0.100, error=0.119\n",
      ">epoch=368, lrate=0.100, error=0.119\n",
      ">epoch=369, lrate=0.100, error=0.119\n",
      ">epoch=370, lrate=0.100, error=0.118\n",
      ">epoch=371, lrate=0.100, error=0.118\n",
      ">epoch=372, lrate=0.100, error=0.118\n",
      ">epoch=373, lrate=0.100, error=0.117\n",
      ">epoch=374, lrate=0.100, error=0.117\n",
      ">epoch=375, lrate=0.100, error=0.116\n",
      ">epoch=376, lrate=0.100, error=0.116\n",
      ">epoch=377, lrate=0.100, error=0.116\n",
      ">epoch=378, lrate=0.100, error=0.115\n",
      ">epoch=379, lrate=0.100, error=0.115\n",
      ">epoch=380, lrate=0.100, error=0.115\n",
      ">epoch=381, lrate=0.100, error=0.114\n",
      ">epoch=382, lrate=0.100, error=0.114\n",
      ">epoch=383, lrate=0.100, error=0.114\n",
      ">epoch=384, lrate=0.100, error=0.113\n",
      ">epoch=385, lrate=0.100, error=0.113\n",
      ">epoch=386, lrate=0.100, error=0.113\n",
      ">epoch=387, lrate=0.100, error=0.112\n",
      ">epoch=388, lrate=0.100, error=0.112\n",
      ">epoch=389, lrate=0.100, error=0.112\n",
      ">epoch=390, lrate=0.100, error=0.111\n",
      ">epoch=391, lrate=0.100, error=0.111\n",
      ">epoch=392, lrate=0.100, error=0.111\n",
      ">epoch=393, lrate=0.100, error=0.110\n",
      ">epoch=394, lrate=0.100, error=0.110\n",
      ">epoch=395, lrate=0.100, error=0.110\n",
      ">epoch=396, lrate=0.100, error=0.109\n",
      ">epoch=397, lrate=0.100, error=0.109\n",
      ">epoch=398, lrate=0.100, error=0.109\n",
      ">epoch=399, lrate=0.100, error=0.108\n",
      ">epoch=400, lrate=0.100, error=0.108\n",
      ">epoch=401, lrate=0.100, error=0.108\n",
      ">epoch=402, lrate=0.100, error=0.107\n",
      ">epoch=403, lrate=0.100, error=0.107\n",
      ">epoch=404, lrate=0.100, error=0.107\n",
      ">epoch=405, lrate=0.100, error=0.106\n",
      ">epoch=406, lrate=0.100, error=0.106\n",
      ">epoch=407, lrate=0.100, error=0.106\n",
      ">epoch=408, lrate=0.100, error=0.105\n",
      ">epoch=409, lrate=0.100, error=0.105\n",
      ">epoch=410, lrate=0.100, error=0.105\n",
      ">epoch=411, lrate=0.100, error=0.105\n",
      ">epoch=412, lrate=0.100, error=0.104\n",
      ">epoch=413, lrate=0.100, error=0.104\n",
      ">epoch=414, lrate=0.100, error=0.104\n",
      ">epoch=415, lrate=0.100, error=0.103\n",
      ">epoch=416, lrate=0.100, error=0.103\n",
      ">epoch=417, lrate=0.100, error=0.103\n",
      ">epoch=418, lrate=0.100, error=0.103\n",
      ">epoch=419, lrate=0.100, error=0.102\n",
      ">epoch=420, lrate=0.100, error=0.102\n",
      ">epoch=421, lrate=0.100, error=0.102\n",
      ">epoch=422, lrate=0.100, error=0.101\n",
      ">epoch=423, lrate=0.100, error=0.101\n",
      ">epoch=424, lrate=0.100, error=0.101\n",
      ">epoch=425, lrate=0.100, error=0.101\n",
      ">epoch=426, lrate=0.100, error=0.100\n",
      ">epoch=427, lrate=0.100, error=0.100\n",
      ">epoch=428, lrate=0.100, error=0.100\n",
      ">epoch=429, lrate=0.100, error=0.099\n",
      ">epoch=430, lrate=0.100, error=0.099\n",
      ">epoch=431, lrate=0.100, error=0.099\n",
      ">epoch=432, lrate=0.100, error=0.099\n",
      ">epoch=433, lrate=0.100, error=0.098\n",
      ">epoch=434, lrate=0.100, error=0.098\n",
      ">epoch=435, lrate=0.100, error=0.098\n",
      ">epoch=436, lrate=0.100, error=0.098\n",
      ">epoch=437, lrate=0.100, error=0.097\n",
      ">epoch=438, lrate=0.100, error=0.097\n",
      ">epoch=439, lrate=0.100, error=0.097\n",
      ">epoch=440, lrate=0.100, error=0.097\n",
      ">epoch=441, lrate=0.100, error=0.096\n",
      ">epoch=442, lrate=0.100, error=0.096\n",
      ">epoch=443, lrate=0.100, error=0.096\n",
      ">epoch=444, lrate=0.100, error=0.096\n",
      ">epoch=445, lrate=0.100, error=0.095\n",
      ">epoch=446, lrate=0.100, error=0.095\n",
      ">epoch=447, lrate=0.100, error=0.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=448, lrate=0.100, error=0.095\n",
      ">epoch=449, lrate=0.100, error=0.094\n",
      ">epoch=450, lrate=0.100, error=0.094\n",
      ">epoch=451, lrate=0.100, error=0.094\n",
      ">epoch=452, lrate=0.100, error=0.094\n",
      ">epoch=453, lrate=0.100, error=0.093\n",
      ">epoch=454, lrate=0.100, error=0.093\n",
      ">epoch=455, lrate=0.100, error=0.093\n",
      ">epoch=456, lrate=0.100, error=0.093\n",
      ">epoch=457, lrate=0.100, error=0.092\n",
      ">epoch=458, lrate=0.100, error=0.092\n",
      ">epoch=459, lrate=0.100, error=0.092\n",
      ">epoch=460, lrate=0.100, error=0.092\n",
      ">epoch=461, lrate=0.100, error=0.091\n",
      ">epoch=462, lrate=0.100, error=0.091\n",
      ">epoch=463, lrate=0.100, error=0.091\n",
      ">epoch=464, lrate=0.100, error=0.091\n",
      ">epoch=465, lrate=0.100, error=0.091\n",
      ">epoch=466, lrate=0.100, error=0.090\n",
      ">epoch=467, lrate=0.100, error=0.090\n",
      ">epoch=468, lrate=0.100, error=0.090\n",
      ">epoch=469, lrate=0.100, error=0.090\n",
      ">epoch=470, lrate=0.100, error=0.089\n",
      ">epoch=471, lrate=0.100, error=0.089\n",
      ">epoch=472, lrate=0.100, error=0.089\n",
      ">epoch=473, lrate=0.100, error=0.089\n",
      ">epoch=474, lrate=0.100, error=0.089\n",
      ">epoch=475, lrate=0.100, error=0.088\n",
      ">epoch=476, lrate=0.100, error=0.088\n",
      ">epoch=477, lrate=0.100, error=0.088\n",
      ">epoch=478, lrate=0.100, error=0.088\n",
      ">epoch=479, lrate=0.100, error=0.087\n",
      ">epoch=480, lrate=0.100, error=0.087\n",
      ">epoch=481, lrate=0.100, error=0.087\n",
      ">epoch=482, lrate=0.100, error=0.087\n",
      ">epoch=483, lrate=0.100, error=0.087\n",
      ">epoch=484, lrate=0.100, error=0.086\n",
      ">epoch=485, lrate=0.100, error=0.086\n",
      ">epoch=486, lrate=0.100, error=0.086\n",
      ">epoch=487, lrate=0.100, error=0.086\n",
      ">epoch=488, lrate=0.100, error=0.086\n",
      ">epoch=489, lrate=0.100, error=0.085\n",
      ">epoch=490, lrate=0.100, error=0.085\n",
      ">epoch=491, lrate=0.100, error=0.085\n",
      ">epoch=492, lrate=0.100, error=0.085\n",
      ">epoch=493, lrate=0.100, error=0.085\n",
      ">epoch=494, lrate=0.100, error=0.084\n",
      ">epoch=495, lrate=0.100, error=0.084\n",
      ">epoch=496, lrate=0.100, error=0.084\n",
      ">epoch=497, lrate=0.100, error=0.084\n",
      ">epoch=498, lrate=0.100, error=0.084\n",
      ">epoch=499, lrate=0.100, error=0.083\n"
     ]
    }
   ],
   "source": [
    "dataset = load_csv('neural_network_input.csv')\n",
    "\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "train=dataset[:230]\n",
    "test=dataset[230:]\n",
    "\n",
    "#put everything together\n",
    "n_folds = 5\n",
    "learning_rate = 0.1\n",
    "n_epoch = 500\n",
    "n_layers = 5\n",
    "n_inputs = len(train[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in train]))\n",
    "network = initialize_network(n_inputs, n_layers, n_outputs)\n",
    "train_network(network, train, learning_rate, n_epoch, n_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 100.0%\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for row in test:\n",
    "    prediction = predict(network, row)\n",
    "    actual=row[-1]\n",
    "    if prediction==actual:\n",
    "        counter+=1\n",
    "print(\"The accuracy is \" + str(counter/len(test)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(network , open( 'combined_network_weights.pkl' , 'wb' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
