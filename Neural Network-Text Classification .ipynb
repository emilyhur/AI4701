{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MTfCZ4lTIm6M",
    "outputId": "2af716b6-b7d9-4761-939b-c77acccf6e75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from cleantext import clean\n",
    "import string\n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import randrange\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oY8V76sSIm6Q"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle  \n",
    "import numpy as np\n",
    "\n",
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text\n",
    "#instead of removing emojis, converts them to text \n",
    "df=pd.read_excel('Copy of Bot Data.xlsx')\n",
    "\n",
    "#convert text to lower case \n",
    "df['biography']=df['biography'].str.lower()\n",
    "df['comment']=df['comment'].str.lower()\n",
    "\n",
    "#expand contractions \n",
    "contractions_dict = {\"aren't\": \"are not\", \"don't\": \"do not\", \"Don't\": \"do not\", \"I'm\": \"I am\", \"i'm\": \"I am\", \n",
    "                    \"it's\": \"it is\", \"y'all\": \"you all\", \"Y'all\": \"you all\", \"didn't\": \"did not\", \"won't\": \"will not\",\n",
    "                   \"I'll\": \"I will\", \"i'll\": \"I will\", \"can't\": \"can not\"}\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(text, expand_dict):\n",
    "    def replace(match):\n",
    "        return expand_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "df['biography']=df['biography'].apply(lambda x:expand_contractions(x, contractions_dict ))\n",
    "df['comment']=df['comment'].apply(lambda x:expand_contractions(x, contractions_dict))\n",
    "\n",
    "bios=df['biography'].astype(str)\n",
    "usernames=df['Username']\n",
    "comments=df['comment']\n",
    "new_bios=[]\n",
    "for b in bios: \n",
    "    temp=convert_emojis_to_word(b)\n",
    "    new_bios.append(temp)\n",
    "new_comments=[]\n",
    "for c in comments:\n",
    "    temp=convert_emojis_to_word(c)\n",
    "    new_comments.append(temp)\n",
    "df_filtered=df.copy()\n",
    "df_filtered['biography']=new_bios\n",
    "df_filtered['comment']=new_comments\n",
    "from cleantext import clean\n",
    "\n",
    "new_bios=[]\n",
    "for b in df_filtered['biography']: \n",
    "    temp=clean(b, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_bios.append('None')\n",
    "    else: \n",
    "        new_bios.append(temp)\n",
    "new_comments=[]\n",
    "for c in df_filtered['comment']:\n",
    "    temp=clean(c, no_emoji=True)\n",
    "    temp=temp.replace(\"\\n\", \" \")\n",
    "    if temp=='':\n",
    "        new_comments.append('None')\n",
    "    else: \n",
    "        new_comments.append(temp)\n",
    "\n",
    "df_filtered['biography']=new_bios\n",
    "df_filtered['comment']=new_comments\n",
    "df_filtered['combined']=df_filtered['biography'] + ' ' + df_filtered['comment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AcTcMOYwIm6S"
   },
   "outputs": [],
   "source": [
    "#classifying the biographies and comments combined \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer1 =  CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer1.fit(df_filtered['combined'])\n",
    "text_array = vectorizer1.transform(df_filtered['combined']).toarray()\n",
    "text_df = pd.DataFrame(data=text_array,columns = vectorizer1.get_feature_names())\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "selector1=RFE(estimator=model, n_features_to_select=50, step=1) #chose arbitrarily to select 50 of the most important words out of 2000 to make it more manageable\n",
    "\n",
    "#split dataset into features and labels\n",
    "Y1=df_filtered['bot classification (0-not a bot, 1-bot)']\n",
    "X1=text_df\n",
    "\n",
    "#run RFE\n",
    "rfe1 = selector1.fit_transform(X1, Y1)\n",
    "filter1=(selector1.get_support())\n",
    "\n",
    "##\n",
    "#filter columns using data from RFE\n",
    "filter1=list(filter1)\n",
    "current_cols = list(X1.columns)\n",
    "\n",
    "#figure out which columns to keep\n",
    "important_cols=[]\n",
    "for index in range(len(filter1)):\n",
    "    if (filter1[index])==True:\n",
    "        important_cols.append(current_cols[index])\n",
    "text_df=text_df[important_cols]\n",
    "df_combined=pd.concat([text_df, df_filtered], axis=1)\n",
    "df_combined.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_combined=df_combined.dropna()\n",
    "df_combined=df_combined.drop(['comment', 'biography', 'Username', 'combined'], axis=1)\n",
    "df_combined=df_combined.sample(frac=1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4auTXq96Im6T"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>app</th>\n",
       "      <th>babedrooling_face</th>\n",
       "      <th>bf</th>\n",
       "      <th>bio</th>\n",
       "      <th>bit</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>charlotte_empire</th>\n",
       "      <th>christiana_menkova__fx</th>\n",
       "      <th>...</th>\n",
       "      <th>vilbl</th>\n",
       "      <th>we</th>\n",
       "      <th>youtube</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Following Count</th>\n",
       "      <th>Follower/Following Ratio</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th># of likes on comment</th>\n",
       "      <th>time of comment after post (minutes)</th>\n",
       "      <th>bot classification (0-not a bot, 1-bot)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2372</td>\n",
       "      <td>297</td>\n",
       "      <td>7.986532</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>2412</td>\n",
       "      <td>0.378109</td>\n",
       "      <td>295</td>\n",
       "      <td>440</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>108</td>\n",
       "      <td>31.490741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>268</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2532</td>\n",
       "      <td>1504</td>\n",
       "      <td>1.683511</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>571</td>\n",
       "      <td>4</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>80</td>\n",
       "      <td>6.637500</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  100  app  babedrooling_face  bf  bio  bit  bitcoin  \\\n",
       "170    0    0    0                  0   0    0    0        0   \n",
       "282    0    0    0                  0   0    0    0        0   \n",
       "132    1    1    0                  0   0    0    0        0   \n",
       "65     0    0    0                  0   0    1    0        0   \n",
       "24     0    0    1                  0   0    0    0        0   \n",
       "..   ...  ...  ...                ...  ..  ...  ...      ...   \n",
       "156    0    0    1                  0   0    0    0        0   \n",
       "123    1    0    0                  0   0    0    0        0   \n",
       "15     0    0    0                  0   0    0    0        0   \n",
       "125    0    0    0                  0   0    1    0        0   \n",
       "265    0    0    0                  0   0    0    0        0   \n",
       "\n",
       "     charlotte_empire  christiana_menkova__fx  ...  vilbl  we  youtube  \\\n",
       "170                 0                       0  ...      0   0        0   \n",
       "282                 0                       0  ...      0   0        0   \n",
       "132                 0                       0  ...      0   0        0   \n",
       "65                  0                       0  ...      0   0        0   \n",
       "24                  0                       0  ...      0   0        0   \n",
       "..                ...                     ...  ...    ...  ..      ...   \n",
       "156                 0                       0  ...      0   0        0   \n",
       "123                 0                       0  ...      0   0        0   \n",
       "15                  0                       0  ...      0   0        0   \n",
       "125                 0                       0  ...      0   0        0   \n",
       "265                 0                       0  ...      0   0        0   \n",
       "\n",
       "     Follower Count  Following Count  Follower/Following Ratio  \\\n",
       "170            2372              297                  7.986532   \n",
       "282             912             2412                  0.378109   \n",
       "132            3401              108                 31.490741   \n",
       "65               26              268                  0.097015   \n",
       "24                7               35                  0.200000   \n",
       "..              ...              ...                       ...   \n",
       "156              34              238                  0.142857   \n",
       "123            2532             1504                  1.683511   \n",
       "15                4               39                  0.102564   \n",
       "125             571                4                142.750000   \n",
       "265             531               80                  6.637500   \n",
       "\n",
       "     Number of posts  # of likes on comment   \\\n",
       "170               25                       0   \n",
       "282              295                     440   \n",
       "132                0                       0   \n",
       "65                 0                      96   \n",
       "24                 2                       0   \n",
       "..               ...                     ...   \n",
       "156                0                      23   \n",
       "123                9                       0   \n",
       "15                 0                       1   \n",
       "125                3                     163   \n",
       "265               30                       3   \n",
       "\n",
       "     time of comment after post (minutes)  \\\n",
       "170                                    12   \n",
       "282                                     3   \n",
       "132                                     2   \n",
       "65                                      0   \n",
       "24                                      2   \n",
       "..                                    ...   \n",
       "156                                     1   \n",
       "123                                     1   \n",
       "15                                      0   \n",
       "125                                     1   \n",
       "265                                     9   \n",
       "\n",
       "     bot classification (0-not a bot, 1-bot)  \n",
       "170                                        0  \n",
       "282                                        0  \n",
       "132                                        1  \n",
       "65                                         1  \n",
       "24                                         1  \n",
       "..                                       ...  \n",
       "156                                        1  \n",
       "123                                        1  \n",
       "15                                         1  \n",
       "125                                        1  \n",
       "265                                        0  \n",
       "\n",
       "[314 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.to_csv('data.csv', index=False)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "slICWQ2eIm6T"
   },
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "    return stats\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e8-WE6lVIm6U"
   },
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    " \n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    " \n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    " \n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    " \n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    " \n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    " \n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(neuron['output'] - expected[j])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "            \n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] -= l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VcdF26hiIm6U"
   },
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xJNavM2WIm6V",
    "outputId": "6f5a7492-7a43-435a-da8e-d840ed5ccd49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=160.653\n",
      ">epoch=1, lrate=0.100, error=127.381\n",
      ">epoch=2, lrate=0.100, error=125.300\n",
      ">epoch=3, lrate=0.100, error=122.969\n",
      ">epoch=4, lrate=0.100, error=120.013\n",
      ">epoch=5, lrate=0.100, error=115.888\n",
      ">epoch=6, lrate=0.100, error=109.844\n",
      ">epoch=7, lrate=0.100, error=101.237\n",
      ">epoch=8, lrate=0.100, error=90.289\n",
      ">epoch=9, lrate=0.100, error=78.296\n",
      ">epoch=10, lrate=0.100, error=66.746\n",
      ">epoch=11, lrate=0.100, error=56.596\n",
      ">epoch=12, lrate=0.100, error=48.170\n",
      ">epoch=13, lrate=0.100, error=41.367\n",
      ">epoch=14, lrate=0.100, error=35.907\n",
      ">epoch=15, lrate=0.100, error=31.502\n",
      ">epoch=16, lrate=0.100, error=27.907\n",
      ">epoch=17, lrate=0.100, error=24.938\n",
      ">epoch=18, lrate=0.100, error=22.456\n",
      ">epoch=19, lrate=0.100, error=20.357\n",
      ">epoch=20, lrate=0.100, error=18.563\n",
      ">epoch=21, lrate=0.100, error=17.016\n",
      ">epoch=22, lrate=0.100, error=15.671\n",
      ">epoch=23, lrate=0.100, error=14.493\n",
      ">epoch=24, lrate=0.100, error=13.456\n",
      ">epoch=25, lrate=0.100, error=12.536\n",
      ">epoch=26, lrate=0.100, error=11.718\n",
      ">epoch=27, lrate=0.100, error=10.986\n",
      ">epoch=28, lrate=0.100, error=10.329\n",
      ">epoch=29, lrate=0.100, error=9.737\n",
      ">epoch=30, lrate=0.100, error=9.201\n",
      ">epoch=31, lrate=0.100, error=8.715\n",
      ">epoch=32, lrate=0.100, error=8.272\n",
      ">epoch=33, lrate=0.100, error=7.866\n",
      ">epoch=34, lrate=0.100, error=7.495\n",
      ">epoch=35, lrate=0.100, error=7.153\n",
      ">epoch=36, lrate=0.100, error=6.838\n",
      ">epoch=37, lrate=0.100, error=6.546\n",
      ">epoch=38, lrate=0.100, error=6.276\n",
      ">epoch=39, lrate=0.100, error=6.024\n",
      ">epoch=40, lrate=0.100, error=5.789\n",
      ">epoch=41, lrate=0.100, error=5.570\n",
      ">epoch=42, lrate=0.100, error=5.365\n",
      ">epoch=43, lrate=0.100, error=5.172\n",
      ">epoch=44, lrate=0.100, error=4.991\n",
      ">epoch=45, lrate=0.100, error=4.820\n",
      ">epoch=46, lrate=0.100, error=4.659\n",
      ">epoch=47, lrate=0.100, error=4.507\n",
      ">epoch=48, lrate=0.100, error=4.363\n",
      ">epoch=49, lrate=0.100, error=4.227\n",
      ">epoch=50, lrate=0.100, error=4.098\n",
      ">epoch=51, lrate=0.100, error=3.975\n",
      ">epoch=52, lrate=0.100, error=3.858\n",
      ">epoch=53, lrate=0.100, error=3.747\n",
      ">epoch=54, lrate=0.100, error=3.641\n",
      ">epoch=55, lrate=0.100, error=3.540\n",
      ">epoch=56, lrate=0.100, error=3.444\n",
      ">epoch=57, lrate=0.100, error=3.352\n",
      ">epoch=58, lrate=0.100, error=3.264\n",
      ">epoch=59, lrate=0.100, error=3.180\n",
      ">epoch=60, lrate=0.100, error=3.099\n",
      ">epoch=61, lrate=0.100, error=3.022\n",
      ">epoch=62, lrate=0.100, error=2.948\n",
      ">epoch=63, lrate=0.100, error=2.877\n",
      ">epoch=64, lrate=0.100, error=2.810\n",
      ">epoch=65, lrate=0.100, error=2.744\n",
      ">epoch=66, lrate=0.100, error=2.682\n",
      ">epoch=67, lrate=0.100, error=2.621\n",
      ">epoch=68, lrate=0.100, error=2.564\n",
      ">epoch=69, lrate=0.100, error=2.508\n",
      ">epoch=70, lrate=0.100, error=2.454\n",
      ">epoch=71, lrate=0.100, error=2.403\n",
      ">epoch=72, lrate=0.100, error=2.353\n",
      ">epoch=73, lrate=0.100, error=2.305\n",
      ">epoch=74, lrate=0.100, error=2.259\n",
      ">epoch=75, lrate=0.100, error=2.214\n",
      ">epoch=76, lrate=0.100, error=2.171\n",
      ">epoch=77, lrate=0.100, error=2.129\n",
      ">epoch=78, lrate=0.100, error=2.089\n",
      ">epoch=79, lrate=0.100, error=2.050\n",
      ">epoch=80, lrate=0.100, error=2.013\n",
      ">epoch=81, lrate=0.100, error=1.976\n",
      ">epoch=82, lrate=0.100, error=1.941\n",
      ">epoch=83, lrate=0.100, error=1.907\n",
      ">epoch=84, lrate=0.100, error=1.874\n",
      ">epoch=85, lrate=0.100, error=1.842\n",
      ">epoch=86, lrate=0.100, error=1.811\n",
      ">epoch=87, lrate=0.100, error=1.781\n",
      ">epoch=88, lrate=0.100, error=1.752\n",
      ">epoch=89, lrate=0.100, error=1.723\n",
      ">epoch=90, lrate=0.100, error=1.696\n",
      ">epoch=91, lrate=0.100, error=1.669\n",
      ">epoch=92, lrate=0.100, error=1.643\n",
      ">epoch=93, lrate=0.100, error=1.618\n",
      ">epoch=94, lrate=0.100, error=1.593\n",
      ">epoch=95, lrate=0.100, error=1.570\n",
      ">epoch=96, lrate=0.100, error=1.546\n",
      ">epoch=97, lrate=0.100, error=1.524\n",
      ">epoch=98, lrate=0.100, error=1.502\n",
      ">epoch=99, lrate=0.100, error=1.480\n",
      ">epoch=100, lrate=0.100, error=1.460\n",
      ">epoch=101, lrate=0.100, error=1.439\n",
      ">epoch=102, lrate=0.100, error=1.419\n",
      ">epoch=103, lrate=0.100, error=1.400\n",
      ">epoch=104, lrate=0.100, error=1.381\n",
      ">epoch=105, lrate=0.100, error=1.363\n",
      ">epoch=106, lrate=0.100, error=1.345\n",
      ">epoch=107, lrate=0.100, error=1.327\n",
      ">epoch=108, lrate=0.100, error=1.310\n",
      ">epoch=109, lrate=0.100, error=1.294\n",
      ">epoch=110, lrate=0.100, error=1.277\n",
      ">epoch=111, lrate=0.100, error=1.261\n",
      ">epoch=112, lrate=0.100, error=1.246\n",
      ">epoch=113, lrate=0.100, error=1.231\n",
      ">epoch=114, lrate=0.100, error=1.216\n",
      ">epoch=115, lrate=0.100, error=1.201\n",
      ">epoch=116, lrate=0.100, error=1.187\n",
      ">epoch=117, lrate=0.100, error=1.173\n",
      ">epoch=118, lrate=0.100, error=1.159\n",
      ">epoch=119, lrate=0.100, error=1.146\n",
      ">epoch=120, lrate=0.100, error=1.133\n",
      ">epoch=121, lrate=0.100, error=1.120\n",
      ">epoch=122, lrate=0.100, error=1.108\n",
      ">epoch=123, lrate=0.100, error=1.095\n",
      ">epoch=124, lrate=0.100, error=1.083\n",
      ">epoch=125, lrate=0.100, error=1.072\n",
      ">epoch=126, lrate=0.100, error=1.060\n",
      ">epoch=127, lrate=0.100, error=1.049\n",
      ">epoch=128, lrate=0.100, error=1.038\n",
      ">epoch=129, lrate=0.100, error=1.027\n",
      ">epoch=130, lrate=0.100, error=1.016\n",
      ">epoch=131, lrate=0.100, error=1.006\n",
      ">epoch=132, lrate=0.100, error=0.995\n",
      ">epoch=133, lrate=0.100, error=0.985\n",
      ">epoch=134, lrate=0.100, error=0.975\n",
      ">epoch=135, lrate=0.100, error=0.966\n",
      ">epoch=136, lrate=0.100, error=0.956\n",
      ">epoch=137, lrate=0.100, error=0.947\n",
      ">epoch=138, lrate=0.100, error=0.937\n",
      ">epoch=139, lrate=0.100, error=0.928\n",
      ">epoch=140, lrate=0.100, error=0.920\n",
      ">epoch=141, lrate=0.100, error=0.911\n",
      ">epoch=142, lrate=0.100, error=0.902\n",
      ">epoch=143, lrate=0.100, error=0.894\n",
      ">epoch=144, lrate=0.100, error=0.886\n",
      ">epoch=145, lrate=0.100, error=0.877\n",
      ">epoch=146, lrate=0.100, error=0.869\n",
      ">epoch=147, lrate=0.100, error=0.862\n",
      ">epoch=148, lrate=0.100, error=0.854\n",
      ">epoch=149, lrate=0.100, error=0.846\n",
      ">epoch=150, lrate=0.100, error=0.839\n",
      ">epoch=151, lrate=0.100, error=0.831\n",
      ">epoch=152, lrate=0.100, error=0.824\n",
      ">epoch=153, lrate=0.100, error=0.817\n",
      ">epoch=154, lrate=0.100, error=0.810\n",
      ">epoch=155, lrate=0.100, error=0.803\n",
      ">epoch=156, lrate=0.100, error=0.796\n",
      ">epoch=157, lrate=0.100, error=0.790\n",
      ">epoch=158, lrate=0.100, error=0.783\n",
      ">epoch=159, lrate=0.100, error=0.777\n",
      ">epoch=160, lrate=0.100, error=0.770\n",
      ">epoch=161, lrate=0.100, error=0.764\n",
      ">epoch=162, lrate=0.100, error=0.758\n",
      ">epoch=163, lrate=0.100, error=0.752\n",
      ">epoch=164, lrate=0.100, error=0.746\n",
      ">epoch=165, lrate=0.100, error=0.740\n",
      ">epoch=166, lrate=0.100, error=0.734\n",
      ">epoch=167, lrate=0.100, error=0.728\n",
      ">epoch=168, lrate=0.100, error=0.722\n",
      ">epoch=169, lrate=0.100, error=0.717\n",
      ">epoch=170, lrate=0.100, error=0.711\n",
      ">epoch=171, lrate=0.100, error=0.706\n",
      ">epoch=172, lrate=0.100, error=0.701\n",
      ">epoch=173, lrate=0.100, error=0.695\n",
      ">epoch=174, lrate=0.100, error=0.690\n",
      ">epoch=175, lrate=0.100, error=0.685\n",
      ">epoch=176, lrate=0.100, error=0.680\n",
      ">epoch=177, lrate=0.100, error=0.675\n",
      ">epoch=178, lrate=0.100, error=0.670\n",
      ">epoch=179, lrate=0.100, error=0.665\n",
      ">epoch=180, lrate=0.100, error=0.660\n",
      ">epoch=181, lrate=0.100, error=0.655\n",
      ">epoch=182, lrate=0.100, error=0.651\n",
      ">epoch=183, lrate=0.100, error=0.646\n",
      ">epoch=184, lrate=0.100, error=0.642\n",
      ">epoch=185, lrate=0.100, error=0.637\n",
      ">epoch=186, lrate=0.100, error=0.633\n",
      ">epoch=187, lrate=0.100, error=0.628\n",
      ">epoch=188, lrate=0.100, error=0.624\n",
      ">epoch=189, lrate=0.100, error=0.620\n",
      ">epoch=190, lrate=0.100, error=0.616\n",
      ">epoch=191, lrate=0.100, error=0.611\n",
      ">epoch=192, lrate=0.100, error=0.607\n",
      ">epoch=193, lrate=0.100, error=0.603\n",
      ">epoch=194, lrate=0.100, error=0.599\n",
      ">epoch=195, lrate=0.100, error=0.595\n",
      ">epoch=196, lrate=0.100, error=0.591\n",
      ">epoch=197, lrate=0.100, error=0.587\n",
      ">epoch=198, lrate=0.100, error=0.584\n",
      ">epoch=199, lrate=0.100, error=0.580\n",
      ">epoch=200, lrate=0.100, error=0.576\n",
      ">epoch=201, lrate=0.100, error=0.572\n",
      ">epoch=202, lrate=0.100, error=0.569\n",
      ">epoch=203, lrate=0.100, error=0.565\n",
      ">epoch=204, lrate=0.100, error=0.562\n",
      ">epoch=205, lrate=0.100, error=0.558\n",
      ">epoch=206, lrate=0.100, error=0.555\n",
      ">epoch=207, lrate=0.100, error=0.551\n",
      ">epoch=208, lrate=0.100, error=0.548\n",
      ">epoch=209, lrate=0.100, error=0.545\n",
      ">epoch=210, lrate=0.100, error=0.541\n",
      ">epoch=211, lrate=0.100, error=0.538\n",
      ">epoch=212, lrate=0.100, error=0.535\n",
      ">epoch=213, lrate=0.100, error=0.531\n",
      ">epoch=214, lrate=0.100, error=0.528\n",
      ">epoch=215, lrate=0.100, error=0.525\n",
      ">epoch=216, lrate=0.100, error=0.522\n",
      ">epoch=217, lrate=0.100, error=0.519\n",
      ">epoch=218, lrate=0.100, error=0.516\n",
      ">epoch=219, lrate=0.100, error=0.513\n",
      ">epoch=220, lrate=0.100, error=0.510\n",
      ">epoch=221, lrate=0.100, error=0.507\n",
      ">epoch=222, lrate=0.100, error=0.504\n",
      ">epoch=223, lrate=0.100, error=0.501\n",
      ">epoch=224, lrate=0.100, error=0.498\n",
      ">epoch=225, lrate=0.100, error=0.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=226, lrate=0.100, error=0.493\n",
      ">epoch=227, lrate=0.100, error=0.490\n",
      ">epoch=228, lrate=0.100, error=0.487\n",
      ">epoch=229, lrate=0.100, error=0.485\n",
      ">epoch=230, lrate=0.100, error=0.482\n",
      ">epoch=231, lrate=0.100, error=0.479\n",
      ">epoch=232, lrate=0.100, error=0.477\n",
      ">epoch=233, lrate=0.100, error=0.474\n",
      ">epoch=234, lrate=0.100, error=0.471\n",
      ">epoch=235, lrate=0.100, error=0.469\n",
      ">epoch=236, lrate=0.100, error=0.466\n",
      ">epoch=237, lrate=0.100, error=0.464\n",
      ">epoch=238, lrate=0.100, error=0.461\n",
      ">epoch=239, lrate=0.100, error=0.459\n",
      ">epoch=240, lrate=0.100, error=0.457\n",
      ">epoch=241, lrate=0.100, error=0.454\n",
      ">epoch=242, lrate=0.100, error=0.452\n",
      ">epoch=243, lrate=0.100, error=0.449\n",
      ">epoch=244, lrate=0.100, error=0.447\n",
      ">epoch=245, lrate=0.100, error=0.445\n",
      ">epoch=246, lrate=0.100, error=0.443\n",
      ">epoch=247, lrate=0.100, error=0.440\n",
      ">epoch=248, lrate=0.100, error=0.438\n",
      ">epoch=249, lrate=0.100, error=0.436\n",
      ">epoch=250, lrate=0.100, error=0.434\n",
      ">epoch=251, lrate=0.100, error=0.431\n",
      ">epoch=252, lrate=0.100, error=0.429\n",
      ">epoch=253, lrate=0.100, error=0.427\n",
      ">epoch=254, lrate=0.100, error=0.425\n",
      ">epoch=255, lrate=0.100, error=0.423\n",
      ">epoch=256, lrate=0.100, error=0.421\n",
      ">epoch=257, lrate=0.100, error=0.419\n",
      ">epoch=258, lrate=0.100, error=0.417\n",
      ">epoch=259, lrate=0.100, error=0.415\n",
      ">epoch=260, lrate=0.100, error=0.413\n",
      ">epoch=261, lrate=0.100, error=0.411\n",
      ">epoch=262, lrate=0.100, error=0.409\n",
      ">epoch=263, lrate=0.100, error=0.407\n",
      ">epoch=264, lrate=0.100, error=0.405\n",
      ">epoch=265, lrate=0.100, error=0.403\n",
      ">epoch=266, lrate=0.100, error=0.401\n",
      ">epoch=267, lrate=0.100, error=0.399\n",
      ">epoch=268, lrate=0.100, error=0.397\n",
      ">epoch=269, lrate=0.100, error=0.395\n",
      ">epoch=270, lrate=0.100, error=0.394\n",
      ">epoch=271, lrate=0.100, error=0.392\n",
      ">epoch=272, lrate=0.100, error=0.390\n",
      ">epoch=273, lrate=0.100, error=0.388\n",
      ">epoch=274, lrate=0.100, error=0.386\n",
      ">epoch=275, lrate=0.100, error=0.385\n",
      ">epoch=276, lrate=0.100, error=0.383\n",
      ">epoch=277, lrate=0.100, error=0.381\n",
      ">epoch=278, lrate=0.100, error=0.379\n",
      ">epoch=279, lrate=0.100, error=0.378\n",
      ">epoch=280, lrate=0.100, error=0.376\n",
      ">epoch=281, lrate=0.100, error=0.374\n",
      ">epoch=282, lrate=0.100, error=0.373\n",
      ">epoch=283, lrate=0.100, error=0.371\n",
      ">epoch=284, lrate=0.100, error=0.369\n",
      ">epoch=285, lrate=0.100, error=0.368\n",
      ">epoch=286, lrate=0.100, error=0.366\n",
      ">epoch=287, lrate=0.100, error=0.365\n",
      ">epoch=288, lrate=0.100, error=0.363\n",
      ">epoch=289, lrate=0.100, error=0.362\n",
      ">epoch=290, lrate=0.100, error=0.360\n",
      ">epoch=291, lrate=0.100, error=0.358\n",
      ">epoch=292, lrate=0.100, error=0.357\n",
      ">epoch=293, lrate=0.100, error=0.355\n",
      ">epoch=294, lrate=0.100, error=0.354\n",
      ">epoch=295, lrate=0.100, error=0.352\n",
      ">epoch=296, lrate=0.100, error=0.351\n",
      ">epoch=297, lrate=0.100, error=0.349\n",
      ">epoch=298, lrate=0.100, error=0.348\n",
      ">epoch=299, lrate=0.100, error=0.347\n",
      ">epoch=300, lrate=0.100, error=0.345\n",
      ">epoch=301, lrate=0.100, error=0.344\n",
      ">epoch=302, lrate=0.100, error=0.342\n",
      ">epoch=303, lrate=0.100, error=0.341\n",
      ">epoch=304, lrate=0.100, error=0.339\n",
      ">epoch=305, lrate=0.100, error=0.338\n",
      ">epoch=306, lrate=0.100, error=0.337\n",
      ">epoch=307, lrate=0.100, error=0.335\n",
      ">epoch=308, lrate=0.100, error=0.334\n",
      ">epoch=309, lrate=0.100, error=0.333\n",
      ">epoch=310, lrate=0.100, error=0.331\n",
      ">epoch=311, lrate=0.100, error=0.330\n",
      ">epoch=312, lrate=0.100, error=0.329\n",
      ">epoch=313, lrate=0.100, error=0.327\n",
      ">epoch=314, lrate=0.100, error=0.326\n",
      ">epoch=315, lrate=0.100, error=0.325\n",
      ">epoch=316, lrate=0.100, error=0.323\n",
      ">epoch=317, lrate=0.100, error=0.322\n",
      ">epoch=318, lrate=0.100, error=0.321\n",
      ">epoch=319, lrate=0.100, error=0.320\n",
      ">epoch=320, lrate=0.100, error=0.318\n",
      ">epoch=321, lrate=0.100, error=0.317\n",
      ">epoch=322, lrate=0.100, error=0.316\n",
      ">epoch=323, lrate=0.100, error=0.315\n",
      ">epoch=324, lrate=0.100, error=0.314\n",
      ">epoch=325, lrate=0.100, error=0.312\n",
      ">epoch=326, lrate=0.100, error=0.311\n",
      ">epoch=327, lrate=0.100, error=0.310\n",
      ">epoch=328, lrate=0.100, error=0.309\n",
      ">epoch=329, lrate=0.100, error=0.308\n",
      ">epoch=330, lrate=0.100, error=0.307\n",
      ">epoch=331, lrate=0.100, error=0.305\n",
      ">epoch=332, lrate=0.100, error=0.304\n",
      ">epoch=333, lrate=0.100, error=0.303\n",
      ">epoch=334, lrate=0.100, error=0.302\n",
      ">epoch=335, lrate=0.100, error=0.301\n",
      ">epoch=336, lrate=0.100, error=0.300\n",
      ">epoch=337, lrate=0.100, error=0.299\n",
      ">epoch=338, lrate=0.100, error=0.298\n",
      ">epoch=339, lrate=0.100, error=0.297\n",
      ">epoch=340, lrate=0.100, error=0.295\n",
      ">epoch=341, lrate=0.100, error=0.294\n",
      ">epoch=342, lrate=0.100, error=0.293\n",
      ">epoch=343, lrate=0.100, error=0.292\n",
      ">epoch=344, lrate=0.100, error=0.291\n",
      ">epoch=345, lrate=0.100, error=0.290\n",
      ">epoch=346, lrate=0.100, error=0.289\n",
      ">epoch=347, lrate=0.100, error=0.288\n",
      ">epoch=348, lrate=0.100, error=0.287\n",
      ">epoch=349, lrate=0.100, error=0.286\n",
      ">epoch=350, lrate=0.100, error=0.285\n",
      ">epoch=351, lrate=0.100, error=0.284\n",
      ">epoch=352, lrate=0.100, error=0.283\n",
      ">epoch=353, lrate=0.100, error=0.282\n",
      ">epoch=354, lrate=0.100, error=0.281\n",
      ">epoch=355, lrate=0.100, error=0.280\n",
      ">epoch=356, lrate=0.100, error=0.279\n",
      ">epoch=357, lrate=0.100, error=0.278\n",
      ">epoch=358, lrate=0.100, error=0.277\n",
      ">epoch=359, lrate=0.100, error=0.276\n",
      ">epoch=360, lrate=0.100, error=0.275\n",
      ">epoch=361, lrate=0.100, error=0.274\n",
      ">epoch=362, lrate=0.100, error=0.274\n",
      ">epoch=363, lrate=0.100, error=0.273\n",
      ">epoch=364, lrate=0.100, error=0.272\n",
      ">epoch=365, lrate=0.100, error=0.271\n",
      ">epoch=366, lrate=0.100, error=0.270\n",
      ">epoch=367, lrate=0.100, error=0.269\n",
      ">epoch=368, lrate=0.100, error=0.268\n",
      ">epoch=369, lrate=0.100, error=0.267\n",
      ">epoch=370, lrate=0.100, error=0.266\n",
      ">epoch=371, lrate=0.100, error=0.265\n",
      ">epoch=372, lrate=0.100, error=0.265\n",
      ">epoch=373, lrate=0.100, error=0.264\n",
      ">epoch=374, lrate=0.100, error=0.263\n",
      ">epoch=375, lrate=0.100, error=0.262\n",
      ">epoch=376, lrate=0.100, error=0.261\n",
      ">epoch=377, lrate=0.100, error=0.260\n",
      ">epoch=378, lrate=0.100, error=0.259\n",
      ">epoch=379, lrate=0.100, error=0.259\n",
      ">epoch=380, lrate=0.100, error=0.258\n",
      ">epoch=381, lrate=0.100, error=0.257\n",
      ">epoch=382, lrate=0.100, error=0.256\n",
      ">epoch=383, lrate=0.100, error=0.255\n",
      ">epoch=384, lrate=0.100, error=0.254\n",
      ">epoch=385, lrate=0.100, error=0.254\n",
      ">epoch=386, lrate=0.100, error=0.253\n",
      ">epoch=387, lrate=0.100, error=0.252\n",
      ">epoch=388, lrate=0.100, error=0.251\n",
      ">epoch=389, lrate=0.100, error=0.250\n",
      ">epoch=390, lrate=0.100, error=0.250\n",
      ">epoch=391, lrate=0.100, error=0.249\n",
      ">epoch=392, lrate=0.100, error=0.248\n",
      ">epoch=393, lrate=0.100, error=0.247\n",
      ">epoch=394, lrate=0.100, error=0.247\n",
      ">epoch=395, lrate=0.100, error=0.246\n",
      ">epoch=396, lrate=0.100, error=0.245\n",
      ">epoch=397, lrate=0.100, error=0.244\n",
      ">epoch=398, lrate=0.100, error=0.243\n",
      ">epoch=399, lrate=0.100, error=0.243\n",
      ">epoch=400, lrate=0.100, error=0.242\n",
      ">epoch=401, lrate=0.100, error=0.241\n",
      ">epoch=402, lrate=0.100, error=0.241\n",
      ">epoch=403, lrate=0.100, error=0.240\n",
      ">epoch=404, lrate=0.100, error=0.239\n",
      ">epoch=405, lrate=0.100, error=0.238\n",
      ">epoch=406, lrate=0.100, error=0.238\n",
      ">epoch=407, lrate=0.100, error=0.237\n",
      ">epoch=408, lrate=0.100, error=0.236\n",
      ">epoch=409, lrate=0.100, error=0.236\n",
      ">epoch=410, lrate=0.100, error=0.235\n",
      ">epoch=411, lrate=0.100, error=0.234\n",
      ">epoch=412, lrate=0.100, error=0.233\n",
      ">epoch=413, lrate=0.100, error=0.233\n",
      ">epoch=414, lrate=0.100, error=0.232\n",
      ">epoch=415, lrate=0.100, error=0.231\n",
      ">epoch=416, lrate=0.100, error=0.231\n",
      ">epoch=417, lrate=0.100, error=0.230\n",
      ">epoch=418, lrate=0.100, error=0.229\n",
      ">epoch=419, lrate=0.100, error=0.229\n",
      ">epoch=420, lrate=0.100, error=0.228\n",
      ">epoch=421, lrate=0.100, error=0.227\n",
      ">epoch=422, lrate=0.100, error=0.227\n",
      ">epoch=423, lrate=0.100, error=0.226\n",
      ">epoch=424, lrate=0.100, error=0.225\n",
      ">epoch=425, lrate=0.100, error=0.225\n",
      ">epoch=426, lrate=0.100, error=0.224\n",
      ">epoch=427, lrate=0.100, error=0.223\n",
      ">epoch=428, lrate=0.100, error=0.223\n",
      ">epoch=429, lrate=0.100, error=0.222\n",
      ">epoch=430, lrate=0.100, error=0.222\n",
      ">epoch=431, lrate=0.100, error=0.221\n",
      ">epoch=432, lrate=0.100, error=0.220\n",
      ">epoch=433, lrate=0.100, error=0.220\n",
      ">epoch=434, lrate=0.100, error=0.219\n",
      ">epoch=435, lrate=0.100, error=0.218\n",
      ">epoch=436, lrate=0.100, error=0.218\n",
      ">epoch=437, lrate=0.100, error=0.217\n",
      ">epoch=438, lrate=0.100, error=0.217\n",
      ">epoch=439, lrate=0.100, error=0.216\n",
      ">epoch=440, lrate=0.100, error=0.215\n",
      ">epoch=441, lrate=0.100, error=0.215\n",
      ">epoch=442, lrate=0.100, error=0.214\n",
      ">epoch=443, lrate=0.100, error=0.214\n",
      ">epoch=444, lrate=0.100, error=0.213\n",
      ">epoch=445, lrate=0.100, error=0.213\n",
      ">epoch=446, lrate=0.100, error=0.212\n",
      ">epoch=447, lrate=0.100, error=0.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=448, lrate=0.100, error=0.211\n",
      ">epoch=449, lrate=0.100, error=0.210\n",
      ">epoch=450, lrate=0.100, error=0.210\n",
      ">epoch=451, lrate=0.100, error=0.209\n",
      ">epoch=452, lrate=0.100, error=0.209\n",
      ">epoch=453, lrate=0.100, error=0.208\n",
      ">epoch=454, lrate=0.100, error=0.207\n",
      ">epoch=455, lrate=0.100, error=0.207\n",
      ">epoch=456, lrate=0.100, error=0.206\n",
      ">epoch=457, lrate=0.100, error=0.206\n",
      ">epoch=458, lrate=0.100, error=0.205\n",
      ">epoch=459, lrate=0.100, error=0.205\n",
      ">epoch=460, lrate=0.100, error=0.204\n",
      ">epoch=461, lrate=0.100, error=0.204\n",
      ">epoch=462, lrate=0.100, error=0.203\n",
      ">epoch=463, lrate=0.100, error=0.203\n",
      ">epoch=464, lrate=0.100, error=0.202\n",
      ">epoch=465, lrate=0.100, error=0.201\n",
      ">epoch=466, lrate=0.100, error=0.201\n",
      ">epoch=467, lrate=0.100, error=0.200\n",
      ">epoch=468, lrate=0.100, error=0.200\n",
      ">epoch=469, lrate=0.100, error=0.199\n",
      ">epoch=470, lrate=0.100, error=0.199\n",
      ">epoch=471, lrate=0.100, error=0.198\n",
      ">epoch=472, lrate=0.100, error=0.198\n",
      ">epoch=473, lrate=0.100, error=0.197\n",
      ">epoch=474, lrate=0.100, error=0.197\n",
      ">epoch=475, lrate=0.100, error=0.196\n",
      ">epoch=476, lrate=0.100, error=0.196\n",
      ">epoch=477, lrate=0.100, error=0.195\n",
      ">epoch=478, lrate=0.100, error=0.195\n",
      ">epoch=479, lrate=0.100, error=0.194\n",
      ">epoch=480, lrate=0.100, error=0.194\n",
      ">epoch=481, lrate=0.100, error=0.193\n",
      ">epoch=482, lrate=0.100, error=0.193\n",
      ">epoch=483, lrate=0.100, error=0.192\n",
      ">epoch=484, lrate=0.100, error=0.192\n",
      ">epoch=485, lrate=0.100, error=0.191\n",
      ">epoch=486, lrate=0.100, error=0.191\n",
      ">epoch=487, lrate=0.100, error=0.191\n",
      ">epoch=488, lrate=0.100, error=0.190\n",
      ">epoch=489, lrate=0.100, error=0.190\n",
      ">epoch=490, lrate=0.100, error=0.189\n",
      ">epoch=491, lrate=0.100, error=0.189\n",
      ">epoch=492, lrate=0.100, error=0.188\n",
      ">epoch=493, lrate=0.100, error=0.188\n",
      ">epoch=494, lrate=0.100, error=0.187\n",
      ">epoch=495, lrate=0.100, error=0.187\n",
      ">epoch=496, lrate=0.100, error=0.186\n",
      ">epoch=497, lrate=0.100, error=0.186\n",
      ">epoch=498, lrate=0.100, error=0.185\n",
      ">epoch=499, lrate=0.100, error=0.185\n",
      "The accuracy is 98.4126984126984%\n"
     ]
    }
   ],
   "source": [
    "dataset = load_csv('data.csv')\n",
    "\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "train=dataset[:251]\n",
    "test=dataset[251:]\n",
    "\n",
    "#put everything together\n",
    "n_folds = 5\n",
    "learning_rate = 0.1\n",
    "n_epoch = 500\n",
    "n_layers = 5\n",
    "n_inputs = len(train[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in train]))\n",
    "network = initialize_network(n_inputs, n_layers, n_outputs)\n",
    "train_network(network, train, learning_rate, n_epoch, n_outputs)\n",
    "\n",
    "counter=0\n",
    "for row in test:\n",
    "    prediction = predict(network, row)\n",
    "    actual=row[-1]\n",
    "    if prediction==actual:\n",
    "        counter+=1\n",
    "print(\"The accuracy is \" + str(counter/len(test)*100) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(network , open( 'text_network_weights.pkl' , 'wb' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS 4701 Project- Neural Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
